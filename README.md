# Emergent Preference Specialization in LLM Agent Populations

<p align="center">
  <img src="assets/cover.jpeg" alt="Emergent Specialization" width="600"/>
</p>

<p align="center">
  <a href="#overview">Overview</a> â€¢
  <a href="#key-results">Key Results</a> â€¢
  <a href="#theoretical-foundation">Theory</a> â€¢
  <a href="#synthetic-rules">Rules</a> â€¢
  <a href="#quick-start">Quick Start</a> â€¢
  <a href="#experiments">Experiments</a> â€¢
  <a href="docs/DEEP_DIVE.md">ðŸ“š Deep Dive</a> â€¢
  <a href="#citation">Citation</a>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Status-Research%20Paper-blue" alt="Status"/>
  <img src="https://img.shields.io/badge/Python-3.9+-green" alt="Python"/>
  <img src="https://img.shields.io/badge/Rules-8-orange" alt="Rules"/>
  <img src="https://img.shields.io/badge/Causality-70.7%25-purple" alt="Causality"/>
  <img src="https://img.shields.io/badge/Theorems-3-red" alt="Theorems"/>
  <img src="https://img.shields.io/badge/License-MIT-yellow" alt="License"/>
</p>

---

## ðŸ“„ Research Paper

**Author:** Yuhao Li
**Institution:** University of Pennsylvania
**Email:** li88@sas.upenn.edu

This repository contains the complete implementation, experiments, and theoretical analysis for research on emergent preference specialization in LLM agent populations.

---

## Overview

**Can LLM agents develop specialized preferences through competitive selection?**

We demonstrate that populations of initially identical LLM agents can develop specialized *preferences* through competitive selection, without any gradient-based training or external reward shaping.

```
Generation 0                         Generation 100
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ "I am a general-purpose AI..." â”‚   â”‚ "You are a VOWEL SPECIALIST.   â”‚
â”‚                                â”‚   â”‚  Pick words starting with      â”‚
â”‚ Strategies: {}                 â”‚â†’â†’â†’â”‚  A, E, I, O, U..."             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     (12 identical agents)               (8 distinct specialists)
```

### Key Contributions

1. **First causal demonstration** of prompt-based specialization: **70.7% causality rate** (95% CI: [68.3%, 73.1%])
2. **Complete theoretical framework** with 3 proven theorems and equilibrium analysis
3. **Practical benefit demonstration**: Specialized populations outperform generalists by **+60.8pp Â± 9.6pp** (n=5, 95% CI: [48.9, 72.7]) with **5-7 task break-even**
4. **Cross-LLM validation**: Mechanism works across Gemini, GPT-4, and Claude

---

## Key Results

### ðŸŽ¯ Causality Validation (10 Unified Seeds)

| Metric | Value | Interpretation |
|--------|-------|----------------|
| **Swap Test Pass Rate** | **70.7%** | Strong causality proven |
| **95% Confidence Interval** | **[68.3%, 73.1%]** | Tight bounds (4.8% width) |
| **Cohen's d** | **2.66** | Large effect size |
| **Seeds** | 10 (unified gemini-2.5-flash) | All consistent |

### ðŸ“Š Baseline Comparison

| Condition | Accuracy | Improvement |
|-----------|----------|-------------|
| NO_PROMPT | 5.0% | -- |
| RANDOM_PROMPT | 15.0% | +10% |
| WRONG_PROMPT | 20.0% | +15% |
| **CORRECT_PROMPT** | **100.0%** | **+95%** |

### ðŸŒ Cross-LLM Validation (3 Major Providers)

| Model | Provider | Diagonal | Off-Diagonal | Gap |
|-------|----------|----------|--------------|-----|
| **gemini-2.5-flash** | Google | 0.91 | 0.20 | **70.7%** âœ… |
| GPT-4o-mini | OpenAI | 0.90 | 0.37 | 58.6% âœ… |
| Claude 3 Haiku | Anthropic | 0.92 | 0.45 | 50.9% âœ… |

### ðŸ’° Cost-Benefit Analysis

| Metric | Value |
|--------|-------|
| Training Cost | ~$0.00 (free tier) |
| Break-Even Point | **5-7 tasks** |
| Accuracy Improvement | **+60.8pp Â± 9.6pp** (Oracle routing, n=5) |
| ROI | Excellent |

---

## Theoretical Foundation

We provide a complete theoretical framework with three proven theorems:

### Theorem 1: Monotonic Strategy Accumulation âœ…
> The expected total strategy level E[L(t)] is monotonically non-decreasing.

### Theorem 2: Convergence to Specialized Equilibrium âœ…
> Under fitness sharing, the system reaches k â‰¥ âŒŠ(1-Î³)RâŒ‹ distinct L3 specialists within O(NÃ—RÃ—log(1/Îµ)) generations.

### Theorem 3: Stationary Distribution Concentration âœ…
> The stationary distribution Ï€(S*) â‰¥ 1-Îµ for sufficiently large N.

### Additional Analysis
- **Equilibrium Characterization**: Uniqueness (up to permutation), stability, optimality
- **Thompson Sampling Connection**: Links to Paper 1's belief-based mechanism
- **Carrying Capacity**: Optimal N* â‰ˆ 3R (24-32 agents for 8 rules)

See `src/genesis/theory.py` for full proofs.

---

## Synthetic Rules

8 rule domains with cognitive science grounding:

| Category | Rules | Characteristic |
|----------|-------|----------------|
| **Purely Arbitrary** | POSITION, PATTERN, MATH_MOD | No prior knowledge helps |
| **Semi-Arbitrary** | RHYME, ALPHABET, VOWEL_START | Requires rule application |
| **Knowledge-Aided** | ANIMATE, INVERSE | Leverages categorical knowledge |

| Rule | Description | Cognitive Source |
|------|-------------|------------------|
| POSITION | Answer at position B | Serial Position Effect |
| PATTERN | ABAB alternation | Gestalt Psychology |
| INVERSE | Opposite of obvious | Propositional Logic |
| VOWEL_START | Starts with A,E,I,O,U | Phonemic Awareness |
| RHYME | Rhymes with CAT | Phonological Processing |
| ALPHABET | First letter closest to M | Orthographic Processing |
| MATH_MOD | Length mod 3 = 1 | Number Cognition |
| ANIMATE | Living thing (animal) | Category-Specific Processing |

---

## Quick Start

### Installation

```bash
git clone https://github.com/HowardLiYH/Emergent-Prompt-Evolution.git
cd Emergent-Prompt-Evolution
pip install -r requirements.txt

# Set API key in .env file
echo "GOOGLE_API_KEY=your-key" > .env
```

### Run Main Experiments

```bash
# Phase 2: Causality Test (main result)
python experiments/exp_phase2_enhanced.py

# 5-Condition Practical Benefit
python experiments/exp_practical_benefit.py

# Fitness Sharing Ablation
python experiments/exp_fitness_sensitivity.py

# N=48 Scalability Investigation
python experiments/exp_n48_investigation.py
```

---

## Experiments

### Complete Experiment Suite

| Phase | Experiment | Question | File |
|-------|------------|----------|------|
| 0 | Rule Validation | Are rules distinct? | `exp_rule_validation.py` |
| 1 | Preference Emergence | Do agents specialize? | `exp_preference_main.py` |
| **2** | **Causality Test** | **Do prompts cause it?** | `exp_phase2_enhanced.py` |
| 3 | Ablation | Which components matter? | `exp_preference_ablation.py` |
| 4 | MMLU Validation | Transfer to real tasks? | `exp_mmlu_validation.py` |
| 5 | Practical Benefit | Population vs generalist? | `exp_practical_benefit.py` |
| 6 | Cost-Benefit | When does it pay off? | `exp_cost_benefit.py` |
| 7 | Bridge | Synthetic vs real transfer? | `exp_bridge.py` |
| 8 | Falsification | Preference vs capability? | `exp_falsification.py` |

### Key Mechanisms

1. **Strategy Accumulation**: Winners gain rule knowledge (Level 0â†’1â†’2â†’3)
2. **Exclusivity**: Level 3 agents specialize in one rule only
3. **Confidence-based Competition**: Highest confidence among correct wins
4. **Fitness Sharing**: 1/âˆšn penalty promotes diversity
5. **Option B+ Initialization**: Each agent starts with L1 in one random rule

---

## Project Structure

```
emergent_prompt_evolution/
â”œâ”€â”€ src/genesis/
â”‚   â”œâ”€â”€ synthetic_rules.py      # 8 rules + categories
â”‚   â”œâ”€â”€ rule_strategies.py      # 3-level strategies
â”‚   â”œâ”€â”€ preference_agent.py     # Agent with exclusivity
â”‚   â”œâ”€â”€ competition_v3.py       # Confidence-based competition
â”‚   â”œâ”€â”€ llm_client.py           # Unified LLM wrapper
â”‚   â”œâ”€â”€ theory.py               # NEW: 3 theorems + proofs
â”‚   â”œâ”€â”€ real_tasks.py           # NEW: Multi-domain tasks
â”‚   â”œâ”€â”€ routing.py              # NEW: 4 routing methods
â”‚   â”œâ”€â”€ statistics_complete.py  # NEW: Full statistical rigor
â”‚   â”œâ”€â”€ hero_visualization.py   # NEW: Publication figures
â”‚   â”œâ”€â”€ analysis.py             # Bootstrap CIs (10k)
â”‚   â””â”€â”€ neurips_metrics.py      # SCI, HHI, Gini
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ exp_phase2_enhanced.py  # Main causality test
â”‚   â”œâ”€â”€ exp_practical_benefit.py# 5-condition comparison
â”‚   â”œâ”€â”€ exp_falsification.py    # Preference vs capability
â”‚   â”œâ”€â”€ exp_cost_benefit.py     # ROI analysis
â”‚   â”œâ”€â”€ exp_bridge.py           # Mechanism transfer
â”‚   â”œâ”€â”€ exp_fitness_sensitivity.py # Penalty ablation
â”‚   â”œâ”€â”€ exp_n48_investigation.py# Scalability analysis
â”‚   â””â”€â”€ ...                     # Other experiments
â”œâ”€â”€ paper/
â”‚   â”œâ”€â”€ neurips_2025_final.tex  # Full submission
â”‚   â”œâ”€â”€ section3_theory.tex     # Theory section
â”‚   â”œâ”€â”€ section5_realworld.tex  # Real-world section
â”‚   â””â”€â”€ figures/                # Publication figures
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ unified_gemini25/       # 10-seed results
â”‚   â”œâ”€â”€ practical_benefit/      # 5-condition results
â”‚   â”œâ”€â”€ fitness_sensitivity/    # Ablation results
â”‚   â””â”€â”€ ...                     # Other results
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ PREFERENCE_DEFINITION.md# Formal definition
â”‚   â”œâ”€â”€ COGNITIVE_FRAMING.md    # Revised framing
â”‚   â”œâ”€â”€ PROJECT_STATUS.md       # Status tracker
â”‚   â””â”€â”€ AUDIT_LOG.md            # Data integrity
â”œâ”€â”€ CHANGELOG.md                # Version history
â””â”€â”€ README.md                   # This file
```

---

## Statistical Rigor

All results include complete statistical analysis:

| Requirement | Status |
|-------------|--------|
| Cohen's d for all claims | âœ… |
| 95% Confidence Intervals | âœ… |
| Bootstrap CIs (10k resamples) | âœ… |
| Holm-Bonferroni correction | âœ… |
| Power analysis (10 seeds) | âœ… |
| Welch's t-test | âœ… |

---

## ðŸ“š Deep Dive: Understanding the Method

**New to this project?** Read our comprehensive **[Deep Dive Document](docs/DEEP_DIVE.md)** â€” a ground-up mathematical explanation of the entire methodology.

The Deep Dive covers:
- **Part I**: The Problem and Why It Matters
- **Part II**: Mathematical Foundations (entropy, fitness sharing, Markov chains)
- **Part III**: The Mechanism (rules, strategies, competition)
- **Part IV**: Theoretical Analysis (3 theorems with proofs)
- **Part V**: Experimental Validation (causality tests, statistics)
- **Part VI**: Practical Applications (deployment, ROI)
- **Part VII**: What Makes This Impressive

**Prerequisites**: Basic probability theory and familiarity with LLMs. All advanced concepts are developed from first principles.

---

## Related Projects

| Project | Relationship |
|---------|--------------|
| [Emergent-Specialization](https://github.com/HowardLiYH/Emergent-Specialization-in-Multi-Agent-Systems) | Paper 1: Trading agents (foundation) |
| [Emergent-Civilizations](https://github.com/HowardLiYH/Emergent-Civilizations) | Paper 3: Society dynamics (extension) |

---

## Citation

```bibtex
@article{li2025emergent,
  title={Emergent Preference Specialization in LLM Agent Populations
         Through Competitive Selection},
  author={Li, Yuhao},
  journal={arXiv preprint},
  year={2025}
}
```

---

## License

MIT License - See [LICENSE](LICENSE) for details.

---

<p align="center">
  <b>Part of the Emergent Specialization Research Series</b><br>
  <i>Paper 2 of 3</i>
</p>
