\documentclass[11pt]{article}

% ============================================================================
% PACKAGES
% ============================================================================
\usepackage[margin=1in]{geometry}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{mathtools}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage{booktabs}
\usepackage{array}
\usepackage{xcolor}
\usepackage{tcolorbox}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{tikz}
\usetikzlibrary{arrows.meta, positioning, shapes.geometric}

% ============================================================================
% THEOREM ENVIRONMENTS
% ============================================================================
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}{Definition}
\newtheorem{remark}{Remark}

% ============================================================================
% CUSTOM COMMANDS
% ============================================================================
\newcommand{\R}{\mathbb{R}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\Prob}{\mathbb{P}}
\newcommand{\bx}{\mathbf{x}}
\newcommand{\bs}{\mathbf{s}}
\newcommand{\bS}{\mathbf{S}}

% ============================================================================
% TITLE
% ============================================================================
\title{%
    \textbf{Replicator Dynamics with Fitness Sharing:} \\[0.3em]
    \large A Continuous-Time ODE Model for Emergent Specialization \\
    in Multi-Agent LLM Populations \\[1em]
    \normalsize \textit{AMCS 6035 Group Project Proposal}
}

\author{
    Howard Li \\
    \texttt{li88@sas.upenn.edu} \\
    University of Pennsylvania
}

\date{January 2026}

\begin{document}

\maketitle

% ============================================================================
% ABSTRACT
% ============================================================================
\begin{abstract}
We propose to model emergent preference specialization in Large Language Model (LLM) agent populations through the mathematical framework of \textbf{replicator dynamics with fitness sharing}. Our ongoing research demonstrates that populations of initially identical LLM agents spontaneously develop specialized preferences through competitive selection, achieving 70.7\% causality validation and +64.2 percentage point accuracy improvements. This project aims to derive the continuous-time ODE system governing these dynamics, prove convergence to specialized equilibria using Lyapunov analysis, implement high-order numerical schemes (RK4, implicit methods) to simulate population trajectories, and validate theoretical predictions against our empirical simulation data from 10 experimental seeds. The project bridges \textbf{evolutionary game theory}, \textbf{dynamical systems}, and \textbf{modern AI}, directly connecting to both halves of the AMCS 6035 curriculum: optimization theory (via fitness landscape analysis) and numerical differential equations (via ODE discretization and stability analysis).
\end{abstract}

% ============================================================================
% NOTATION TABLE
% ============================================================================
\vspace{1em}
\begin{tcolorbox}[colback=gray!5!white, colframe=gray!75!black, title=\textbf{Notation Summary}]
\begin{tabular}{@{}ll@{}}
$N$ & Population size (number of agents, typically 12) \\
$R$ & Number of rules/strategies (typically 8) \\
$x_r(t)$ & Fraction of agents specializing in rule $r$ at time $t$ \\
$\bx = (x_1, \ldots, x_R)$ & Population distribution vector on simplex $\Delta^R$ \\
$\ell_{i,r}$ & Strategy level of agent $i$ for rule $r$, $\ell_{i,r} \in \{0,1,2,3\}$ \\
$f_r$ & Base fitness (reward) for rule $r$ (often $f_r = f = 1$) \\
$\gamma$ & Fitness sharing exponent (we use $\gamma = 0.5$) \\
$\phi$ & Diversity potential: $\phi = \sum_{r=1}^R \sqrt{x_r}$ \\
$\bx^*$ & Equilibrium distribution: $x_r^* = 1/R$ for all $r$ \\
$L(\bx)$ & Lyapunov function (KL divergence from equilibrium) \\
$V(\bx)$ & Potential function: $V(\bx) = -\sum_r \sqrt{x_r}$ \\
$\lambda_i$ & Eigenvalues of the Jacobian at equilibrium \\
$\Delta^R$ & Probability simplex: $\{\bx \in \R^R : x_r \geq 0, \sum_r x_r = 1\}$ \\
\end{tabular}
\end{tcolorbox}

% ============================================================================
% SECTION 1: INTRODUCTION AND MOTIVATION
% ============================================================================
\section{Introduction and Motivation}

\subsection{Research Context}

Our ongoing research investigates a fundamental question in multi-agent AI systems:
\begin{quote}
\textit{Can Large Language Model agents develop specialized preferences through competition alone, without gradient-based training or explicit reward shaping?}
\end{quote}

We have demonstrated empirically that populations of initially identical LLM agents can spontaneously develop specialized ``preferences'' for different task domains through a winner-take-all competitive selection mechanism. Key results from our ongoing research include:
\begin{itemize}[nosep]
    \item \textbf{70.7\% causality rate} (95\% CI: [68.3\%, 73.1\%], Cohen's $d = 2.66$)
    \item \textbf{+64.2 percentage point improvement} with oracle routing vs. single generalist
    \item \textbf{Cross-LLM validation} across Gemini, GPT-4, and Claude
    \item \textbf{Complete specialization}: Evolved specialists achieve 100\% accuracy on matched tasks
\end{itemize}

\subsection{The Theoretical Gap}

While our empirical results are strong, the current theoretical framework relies on discrete-time Markov chain analysis. This project proposes to develop a \textbf{continuous-time ODE formulation} using replicator dynamics, which will:
\begin{enumerate}[nosep]
    \item Provide more elegant convergence proofs via Lyapunov analysis
    \item Enable analytical characterization of equilibrium properties
    \item Allow rigorous numerical analysis using course techniques
    \item Connect our work to the rich literature on evolutionary game theory
\end{enumerate}

\subsection{Research Questions and Hypotheses}

This project addresses the following research questions:

\begin{tcolorbox}[colback=green!5!white, colframe=green!75!black, title=\textbf{Research Questions}]
\begin{description}[nosep]
    \item[RQ1:] \textbf{Model Validity} --- Does the continuous-time replicator ODE accurately capture the dynamics of our discrete agent simulation?
    \item[RQ2:] \textbf{Equilibrium Existence} --- Is there a unique interior equilibrium, and what is its structure?
    \item[RQ3:] \textbf{Stability} --- Is the equilibrium globally asymptotically stable? Does it satisfy ESS conditions?
    \item[RQ4:] \textbf{Convergence Rate} --- What is the convergence rate as a function of population size $N$ and number of rules $R$?
    \item[RQ5:] \textbf{Numerical Accuracy} --- How do different numerical schemes (Euler, RK4, implicit) compare in accuracy and stability?
\end{description}
\end{tcolorbox}

\textbf{Hypotheses:}
\begin{enumerate}[nosep]
    \item \textbf{H1}: The uniform distribution $x_r^* = 1/R$ is the unique interior equilibrium.
    \item \textbf{H2}: The equilibrium is globally asymptotically stable with convergence rate $O(1/\sqrt{N})$.
    \item \textbf{H3}: The ODE predictions will match discrete simulation results within 10\% relative error.
    \item \textbf{H4}: RK4 will achieve $O(h^4)$ convergence while preserving simplex constraints.
\end{enumerate}

\subsection{Connection to AMCS 6035}

This project directly applies concepts from both halves of the course:

\begin{table}[h]
\centering
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{Course Topic} & \textbf{Application in Project} & \textbf{Section} \\
\midrule
Unconstrained Optimization & Fitness landscape, gradient flow analysis & \S3.3 \\
Convex Optimization & Potential function, Shahshahani metric & \S3.3 \\
Constrained Optimization & Simplex constraints, boundary analysis & \S3.1, \S3.4 \\
Initial Value Problems (ODEs) & Replicator dynamics ODE system & \S3.1, \S3.2 \\
Numerical Schemes (Euler, RK4) & Forward/Backward Euler, RK4 implementation & \S5.1 \\
Stiffness Analysis & Stiffness ratio, implicit method selection & \S5.3 \\
Stability Regions & Step size constraints for stability & \S5.4 \\
Convergence Analysis & Lyapunov stability, spectral analysis & \S4.2, \S4.4 \\
\bottomrule
\end{tabular}
\caption{Connection between course topics and project components. Section numbers refer to this proposal.}
\end{table}

% ============================================================================
% SECTION 2: BACKGROUND
% ============================================================================
\section{Background and Related Work}

\subsection{Replicator Dynamics: Mathematical Foundation}

The replicator equation, introduced by Taylor \& Jonker (1978), describes the evolution of strategy frequencies in a population under natural selection. For a population with $R$ strategies, let $x_i(t) \in [0,1]$ denote the proportion of agents using strategy $i$ at time $t$, with $\sum_{i=1}^R x_i = 1$.

\begin{definition}[Standard Replicator Equation]
The replicator dynamics are given by the ODE system:
\begin{equation}
\dot{x}_i = x_i \left( f_i(\bx) - \bar{f}(\bx) \right), \quad i = 1, \ldots, R
\label{eq:standard_replicator}
\end{equation}
where $f_i(\bx)$ is the fitness of strategy $i$ and $\bar{f}(\bx) = \sum_{j=1}^R x_j f_j(\bx)$ is the mean population fitness.
\end{definition}

\begin{remark}
The simplex $\Delta^R = \{\bx \in \R^R : x_i \geq 0, \sum_i x_i = 1\}$ is invariant under the dynamics \eqref{eq:standard_replicator}, i.e., if $\bx(0) \in \Delta^R$, then $\bx(t) \in \Delta^R$ for all $t \geq 0$.
\end{remark}

\subsection{Fitness Sharing: Diversity Preservation}

Standard replicator dynamics exhibit winner-take-all behavior: the strategy with highest initial fitness dominates the population. To promote diversity (as observed in our experiments), we introduce \textbf{fitness sharing} (Goldberg \& Richardson, 1987):

\begin{definition}[Fitness Sharing Penalty]
Let $n_i = N \cdot x_i$ be the number of agents in niche $i$. The shared fitness is:
\begin{equation}
\tilde{f}_i(\bx) = \frac{f_i(\bx)}{(N x_i)^\gamma} = \frac{f_i(\bx)}{n_i^\gamma}
\label{eq:fitness_sharing}
\end{equation}
where $\gamma \in (0, 1]$ is the sharing exponent (we use $\gamma = 0.5$ in experiments).
\end{definition}

\subsection{Our Agent Population: State Space}

In our LLM agent system:
\begin{itemize}[nosep]
    \item \textbf{Population}: $N$ agents (typically $N = 12$)
    \item \textbf{Rules}: $R$ task domains (we use $R = 8$ synthetic rules)
    \item \textbf{Strategy Levels}: Each agent has level $\ell_{i,r} \in \{0, 1, 2, 3\}$ for rule $r$
    \item \textbf{Specialization}: An agent is a ``specialist'' for rule $r$ if $\ell_{i,r} = 3$
\end{itemize}

We model the \textbf{distribution of specialists across rules} using the replicator framework.

\subsection{Current Discrete-Time Framework}

Our ongoing research uses a \textbf{discrete-time Markov chain} formulation. We summarize it here to motivate the continuous-time extension proposed in this project.

\subsubsection{State Space and Dynamics}

\begin{definition}[Agent State]
Each agent $i$ has a strategy vector $\boldsymbol{\ell}_i = (\ell_{i,1}, \ldots, \ell_{i,R}) \in \{0, 1, 2, 3\}^R$, where $\ell_{i,r}$ is the strategy level for rule $r$. The population state is $\mathbf{S} = (\boldsymbol{\ell}_1, \ldots, \boldsymbol{\ell}_N)$.
\end{definition}

\begin{definition}[Competition Dynamics (Discrete)]
At each generation $t$:
\begin{enumerate}[nosep]
    \item A rule $r$ is sampled uniformly from $\{1, \ldots, R\}$
    \item All agents attempt the task; accuracy depends on strategy level $\ell_{i,r}$
    \item The \textbf{winner} is the agent with highest confidence among correct responders
    \item Winner's strategy level increases: $\ell_{\text{winner}, r} \leftarrow \min(\ell_{\text{winner}, r} + 1, 3)$
    \item \textbf{Fitness sharing}: Winner probability is penalized by $1/\sqrt{n_r}$ where $n_r$ is the number of specialists in rule $r$
\end{enumerate}
\end{definition}

\subsubsection{Markov Chain Formulation}

The population evolves as a Markov chain on state space $\mathcal{S} = \{0,1,2,3\}^{N \times R}$. Let $n_r(t) = |\{i : \ell_{i,r}(t) = 3\}|$ be the number of specialists in rule $r$ at time $t$.

\begin{definition}[Transition Probabilities]
The transition probability for specialist counts is approximately:
\begin{equation}
\Prob(n_r(t+1) = n_r(t) + 1 \mid \mathbf{S}(t)) \approx \frac{1}{R} \cdot \frac{1/\sqrt{n_r + 1}}{\sum_{s=1}^R 1/\sqrt{n_s + 1}} \cdot p_{\text{correct}}(r)
\end{equation}
where the $1/\sqrt{\cdot}$ terms arise from fitness sharing.
\end{definition}

\subsubsection{Current Theoretical Results}

Our discrete analysis establishes three theorems:

\begin{theorem}[Monotonic Accumulation --- Current Work]
The expected total strategy level $\E[\sum_{i,r} \ell_{i,r}(t)]$ is monotonically non-decreasing in $t$.
\end{theorem}

\begin{theorem}[Convergence to Specialists --- Current Work]
Under fitness sharing with $\gamma > 0$, the system converges to a state with at least $k \geq \lfloor (1-\gamma)R \rfloor$ distinct L3 specialists within $O(NR\log(1/\varepsilon))$ generations.
\end{theorem}

\begin{theorem}[Stationary Distribution --- Current Work]
The Markov chain has a stationary distribution $\pi$ concentrated on states where specialists are distributed across rules: $\pi(\mathbf{S}^*) \geq 1 - \varepsilon$ for the specialized equilibrium $\mathbf{S}^*$.
\end{theorem}

\subsubsection{Motivation for Continuous-Time Extension}

While the discrete Markov chain analysis provides convergence guarantees, it has limitations:
\begin{itemize}[nosep]
    \item \textbf{Proof complexity}: Markov chain convergence proofs require careful coupling arguments
    \item \textbf{No closed-form rates}: Convergence speed is characterized only up to $O(\cdot)$ notation
    \item \textbf{Limited equilibrium analysis}: The stationary distribution is hard to characterize explicitly
    \item \textbf{Disconnected from literature}: Evolutionary game theory primarily uses continuous-time ODEs
\end{itemize}

\textbf{This project} develops the continuous-time ODE formulation, which provides:
\begin{itemize}[nosep]
    \item Elegant Lyapunov stability proofs (standard dynamical systems techniques)
    \item Explicit convergence rates via eigenvalue analysis
    \item Direct connection to replicator dynamics literature
    \item Rigorous numerical analysis using course techniques
\end{itemize}

\subsection{Related Work and Literature Context}

Our work builds on several foundational areas:

\subsubsection{Replicator Dynamics}
The replicator equation was introduced by Taylor \& Jonker (1978) and extensively developed by Hofbauer \& Sigmund (1998). It models frequency-dependent selection where strategies with above-average fitness increase in prevalence. The standard form $\dot{x}_i = x_i(f_i(\bx) - \bar{f}(\bx))$ has been analyzed for numerous game-theoretic applications.

\subsubsection{Fitness Sharing in Evolutionary Computation}
Goldberg \& Richardson (1987) introduced fitness sharing to maintain population diversity in genetic algorithms. The $1/n^\gamma$ penalty prevents premature convergence to a single solution. Our work applies this mechanism to multi-agent LLM populations, showing it promotes niche differentiation.

\subsubsection{Evolutionarily Stable Strategies (ESS)}
Maynard Smith \& Price (1973) and Maynard Smith (1982) established ESS as a refinement of Nash equilibrium for evolutionary contexts. An ESS is uninvadable by rare mutant strategies. We prove our equilibrium satisfies ESS conditions under fitness sharing.

\subsubsection{Information Geometry and Shahshahani Metric}
Shahshahani (1979) introduced the natural Riemannian metric on the probability simplex, later connected to Fisher information by Amari \& Nagaoka (2000). Replicator dynamics can be viewed as gradient flow with respect to this metric, providing geometric insight into convergence.

\subsubsection{Mean-Field Limits}
Kurtz (1970) established conditions under which density-dependent Markov chains converge to deterministic ODEs as population size grows. This justifies our continuous-time approximation of the discrete agent dynamics.

\subsubsection{Multi-Agent Specialization in AI}
Recent work in multi-agent reinforcement learning has studied emergent specialization (e.g., role differentiation in cooperative games). Our contribution is demonstrating that LLM agents can develop human-readable specialized preferences through competition alone, without gradient-based training.

% ============================================================================
% SECTION 3: MATHEMATICAL FORMULATION
% ============================================================================
\section{Mathematical Formulation}

\subsection{The Modified Replicator System}

Let $x_r(t)$ denote the fraction of agents specializing in rule $r$ at time $t$. We derive the following ODE system:

\begin{tcolorbox}[colback=blue!5!white, colframe=blue!75!black, title=\textbf{Main ODE System: Replicator Dynamics with Fitness Sharing}]
\begin{equation}
\dot{x}_r = x_r \left( \frac{f_r}{(N x_r)^\gamma} - \sum_{s=1}^R x_s \cdot \frac{f_s}{(N x_s)^\gamma} \right), \quad r = 1, \ldots, R
\label{eq:main_ode}
\end{equation}
where:
\begin{itemize}[nosep]
    \item $f_r$ = base fitness (reward) for winning on rule $r$ (assumed equal: $f_r = 1$)
    \item $\gamma = 0.5$ = sharing exponent (our experimental value)
    \item $N$ = total population size
\end{itemize}
\end{tcolorbox}

\subsection{Simplified Form for Analysis}

For equal base fitness ($f_r = f$ for all $r$), the system simplifies:

\begin{equation}
\dot{x}_r = f \cdot x_r \left( \frac{1}{(N x_r)^\gamma} - \sum_{s=1}^R \frac{x_s}{(N x_s)^\gamma} \right)
\end{equation}

With $\gamma = 0.5$:
\begin{equation}
\dot{x}_r = \frac{f}{\sqrt{N}} \left( \sqrt{x_r} - x_r \sum_{s=1}^R \sqrt{x_s} \right)
\label{eq:simplified_ode}
\end{equation}

Let $\phi = \sum_{s=1}^R \sqrt{x_s}$ (a key quantity we call the ``diversity potential''). Then:
\begin{equation}
\boxed{\dot{x}_r = \frac{f}{\sqrt{N}} \left( \sqrt{x_r} - \phi \cdot x_r \right)}
\end{equation}

\subsection{Fitness Landscape Interpretation}

Define the potential function:
\begin{equation}
V(\bx) = -\sum_{r=1}^R \sqrt{x_r}
\label{eq:potential}
\end{equation}

\begin{proposition}[Shahshahani Gradient Flow]
The system \eqref{eq:simplified_ode} is a \textbf{gradient ascent} on the \textbf{concave} potential $-V(\bx)$ with respect to the Shahshahani metric (the natural Riemannian metric on the probability simplex):
\begin{equation}
\dot{x}_r = x_r \left( \frac{\partial (-V)}{\partial x_r} - \sum_s x_s \frac{\partial (-V)}{\partial x_s} \right)
\end{equation}
\end{proposition}

\begin{remark}[Corrected Interpretation]
Note that $V(\bx) = -\sum_r \sqrt{x_r}$ is \textbf{concave} (not convex), since $\frac{\partial^2 V}{\partial x_r^2} = \frac{1}{4}x_r^{-3/2} > 0$ implies $-V$ is convex. The dynamics \textbf{maximize} the concave potential $-V$, or equivalently, \textbf{minimize} the convex function $V$. This is gradient \textbf{ascent} on $-V$, not descent on $V$.
\end{remark}

This connects to \textbf{constrained optimization}: the dynamics perform gradient ascent on $-V(\bx)$ with respect to the Shahshahani metric (Fisher-Rao information geometry), subject to the simplex constraint. See Shahshahani (1979) and Amari \& Nagaoka (2000) for the information-geometric foundation.

\subsection{Boundary Analysis}

A critical question: does the ODE have singularities at the simplex boundary where $x_r = 0$?

\begin{proposition}[Positive Invariance of Interior]
\label{prop:boundary}
The interior of the simplex $\text{int}(\Delta^R) = \{\bx \in \Delta^R : x_r > 0 \; \forall r\}$ is \textbf{positively invariant} under the dynamics \eqref{eq:simplified_ode}. That is, if $\bx(0) \in \text{int}(\Delta^R)$, then $\bx(t) \in \text{int}(\Delta^R)$ for all $t \geq 0$.
\end{proposition}

\begin{proof}
At the boundary where $x_r = 0$:
\begin{equation}
\dot{x}_r \big|_{x_r=0} = \frac{f}{\sqrt{N}} \left( \sqrt{0} - 0 \cdot \phi \right) = 0
\end{equation}
Thus the boundary faces are \textbf{invariant}. For trajectories starting in the interior, we show they cannot reach the boundary in finite time. Define $y_r = \log(x_r)$. Then:
\begin{equation}
\dot{y}_r = \frac{\dot{x}_r}{x_r} = \frac{f}{\sqrt{N}} \left( \frac{1}{\sqrt{x_r}} - \phi \right)
\end{equation}
As $x_r \to 0^+$, we have $\dot{y}_r \to +\infty$, meaning $y_r$ is pushed away from $-\infty$. By standard ODE theory, trajectories starting in the interior cannot reach the boundary in finite time.
\end{proof}

\begin{remark}[Handling the Singularity]
Although $\sqrt{x_r}$ appears singular at $x_r = 0$, the full expression $\sqrt{x_r} - \phi \cdot x_r$ vanishes at the boundary, and the vector field is Lipschitz continuous on any compact subset of $\text{int}(\Delta^R)$. This ensures existence and uniqueness of solutions in the interior.
\end{remark}

% ============================================================================
% SECTION 4: THEORETICAL ANALYSIS
% ============================================================================
\section{Theoretical Analysis (Objectives)}

\subsection{Equilibrium Characterization}

\begin{theorem}[Unique Interior Equilibrium]
\label{thm:equilibrium}
The system \eqref{eq:simplified_ode} has a unique interior equilibrium:
\begin{equation}
x_r^* = \frac{1}{R}, \quad r = 1, \ldots, R
\end{equation}
i.e., the uniform distribution where each rule has equal specialist proportion.
\end{theorem}

\begin{proof}
At equilibrium, $\dot{x}_r = 0$ for all $r = 1, \ldots, R$. From \eqref{eq:simplified_ode}:
\begin{equation}
\frac{f}{\sqrt{N}} \left( \sqrt{x_r} - \phi \cdot x_r \right) = 0 \quad \Rightarrow \quad \sqrt{x_r} = \phi \cdot x_r
\end{equation}
for all $r$, where $\phi = \sum_{s=1}^R \sqrt{x_s}$.

\textbf{Case 1:} If $x_r = 0$ for some $r$, then $\sqrt{x_r} = 0 = \phi \cdot 0$, which is satisfied. But we seek \emph{interior} equilibria where $x_r > 0$ for all $r$.

\textbf{Case 2:} For interior points ($x_r > 0$ for all $r$), dividing by $\sqrt{x_r}$ gives:
\begin{equation}
1 = \phi \cdot \sqrt{x_r} \quad \Rightarrow \quad \sqrt{x_r} = \frac{1}{\phi}
\end{equation}
This must hold for all $r$, so $\sqrt{x_r}$ is constant across $r$. Let $\sqrt{x_r} = c$ for all $r$. Then:
\begin{equation}
\phi = \sum_{r=1}^R \sqrt{x_r} = R \cdot c \quad \text{and} \quad \sqrt{x_r} = \frac{1}{\phi} = \frac{1}{Rc}
\end{equation}
Thus $c = 1/(Rc)$, giving $c^2 = 1/R$, so $c = 1/\sqrt{R}$.

Therefore $x_r = c^2 = 1/R$ for all $r$. We verify: $\sum_r x_r = R \cdot (1/R) = 1$ ✓.

\textbf{Uniqueness:} The derivation shows that any interior equilibrium must satisfy $x_r = 1/R$ for all $r$, proving uniqueness.
\end{proof}

\subsection{Lyapunov Stability Analysis}

\begin{theorem}[Global Asymptotic Stability]
\label{thm:stability}
The equilibrium $\bx^* = (1/R, \ldots, 1/R)$ is globally asymptotically stable for initial conditions in the interior of $\Delta^R$.
\end{theorem}

\begin{proof}
We construct a Lyapunov function and verify all conditions rigorously.

\textbf{Step 1: Lyapunov Function.} Define the relative entropy (KL divergence):
\begin{equation}
L(\bx) = D_{\text{KL}}(\bx \| \bx^*) = \sum_{r=1}^R x_r \log\left(\frac{x_r}{x_r^*}\right) = \sum_{r=1}^R x_r \log(R x_r)
\end{equation}

\textbf{Step 2: Positive Definiteness.} By Gibbs' inequality (a consequence of Jensen's inequality applied to the convex function $-\log$):
\begin{equation}
D_{\text{KL}}(\bx \| \bx^*) \geq 0 \quad \text{with equality iff } \bx = \bx^*
\end{equation}
Thus $L(\bx) > 0$ for all $\bx \in \text{int}(\Delta^R) \setminus \{\bx^*\}$ and $L(\bx^*) = 0$.

\textbf{Step 3: Time Derivative.} Computing $\dot{L}$ along trajectories:
\begin{align}
\dot{L} &= \sum_{r=1}^R \frac{\partial L}{\partial x_r} \dot{x}_r = \sum_{r=1}^R (\log(Rx_r) + 1) \dot{x}_r \\
&= \sum_{r=1}^R \log(Rx_r) \dot{x}_r + \underbrace{\sum_{r=1}^R \dot{x}_r}_{=0 \text{ (simplex)}} = \sum_{r=1}^R \log(Rx_r) \dot{x}_r
\end{align}

Substituting $\dot{x}_r = \frac{f}{\sqrt{N}}(\sqrt{x_r} - \phi x_r)$ where $\phi = \sum_s \sqrt{x_s}$:
\begin{equation}
\dot{L} = \frac{f}{\sqrt{N}} \sum_{r=1}^R \log(Rx_r) (\sqrt{x_r} - \phi x_r)
\end{equation}

\textbf{Step 4: Sign Analysis via Rearrangement.} Define $g_r = \sqrt{x_r} > 0$ so that $x_r = g_r^2$ and $\phi = \sum_r g_r$. Note $\sum_r x_r = \sum_r g_r^2 = 1$. Then:
\begin{align}
\dot{L} &= \frac{f}{\sqrt{N}} \sum_r \log(Rg_r^2) (g_r - \phi g_r^2) \\
&= \frac{f}{\sqrt{N}} \sum_r 2\log(g_r\sqrt{R}) (g_r - \phi g_r^2) \\
&= \frac{2f}{\sqrt{N}} \left[ \sum_r g_r \log(g_r\sqrt{R}) - \phi \sum_r g_r^2 \log(g_r\sqrt{R}) \right]
\end{align}

Define the probability measure $\mu_r = g_r^2 = x_r$ (since $\sum_r g_r^2 = 1$) and the function $h(g) = \log(g\sqrt{R})$. Then:
\begin{equation}
\dot{L} = \frac{2f}{\sqrt{N}} \left[ \sum_r g_r h(g_r) - \phi \sum_r \mu_r h(g_r) \right]
\end{equation}

Now, $\sum_r g_r h(g_r) = \sum_r g_r h(g_r)$ and $\sum_r \mu_r h(g_r) = \mathbb{E}_\mu[h(g)]$. Also, $\phi = \sum_r g_r$.

\textbf{Key Inequality:} By the rearrangement inequality and the fact that $g_r \mapsto h(g_r) = \log(g_r\sqrt{R})$ is monotonically increasing, we have:
\begin{equation}
\sum_r g_r h(g_r) \leq \phi \cdot \sum_r g_r^2 h(g_r) / \sum_r g_r^2 = \phi \sum_r \mu_r h(g_r)
\end{equation}
when the $g_r$ are not all equal. Equality holds iff all $g_r$ are equal, i.e., $g_r = 1/\sqrt{R}$ for all $r$, which gives $x_r = 1/R$ for all $r$.

Therefore: $\dot{L} \leq 0$ with equality iff $\bx = \bx^*$.

\textbf{Step 5: LaSalle's Invariance Principle.} By Proposition \ref{prop:boundary}, trajectories starting in $\text{int}(\Delta^R)$ remain in $\text{int}(\Delta^R)$. The sublevel sets $\Omega_c = \{L(\bx) \leq c\} \cap \text{int}(\Delta^R)$ are:
\begin{itemize}
    \item Bounded (since $\Delta^R$ is bounded)
    \item Closed in $\text{int}(\Delta^R)$ (since $L$ is continuous)
    \item Positively invariant (since $\dot{L} \leq 0$)
\end{itemize}

By LaSalle's invariance principle, every trajectory converges to the largest invariant set in $\{\bx : \dot{L} = 0\}$. Since $\dot{L} = 0$ only at $\bx = \bx^*$, the largest invariant set is $\{\bx^*\}$.

Therefore, $\bx^*$ is globally asymptotically stable on $\text{int}(\Delta^R)$.
\end{proof}

\subsection{Evolutionarily Stable Strategy (ESS) Analysis}

Beyond stability, we verify that the equilibrium satisfies the stronger ESS conditions from evolutionary game theory.

\begin{definition}[ESS Conditions]
A strategy $\bx^*$ is an ESS if for all $\mathbf{y} \neq \bx^*$:
\begin{enumerate}
    \item \textbf{Nash condition:} $u(\bx^*, \bx^*) \geq u(\mathbf{y}, \bx^*)$
    \item \textbf{Stability condition:} If equality holds above, then $u(\bx^*, \mathbf{y}) > u(\mathbf{y}, \mathbf{y})$
\end{enumerate}
where $u(\mathbf{a}, \mathbf{b})$ is the payoff to strategy $\mathbf{a}$ against population $\mathbf{b}$.
\end{definition}

\begin{proposition}[Uniform Distribution is ESS]
\label{prop:ess}
Under fitness sharing with $\gamma > 0$, the uniform distribution $\bx^* = (1/R, \ldots, 1/R)$ satisfies the ESS conditions.
\end{proposition}

\begin{proof}
The payoff to a pure strategy $r$ (i.e., $\mathbf{e}_r$) against a population with distribution $\bx$ is the shared fitness:
\begin{equation}
u(\mathbf{e}_r, \bx) = \frac{f}{(Nx_r)^\gamma}
\end{equation}

The payoff to a mixed strategy $\mathbf{y} = (y_1, \ldots, y_R)$ against population $\bx$ is:
\begin{equation}
u(\mathbf{y}, \bx) = \sum_{r=1}^R y_r \cdot u(\mathbf{e}_r, \bx) = \sum_{r=1}^R \frac{f \cdot y_r}{(Nx_r)^\gamma}
\end{equation}

\textbf{Nash Condition.} At $\bx^* = (1/R, \ldots, 1/R)$:
\begin{equation}
u(\mathbf{y}, \bx^*) = \sum_{r=1}^R \frac{f \cdot y_r}{(N/R)^\gamma} = \frac{f R^\gamma}{N^\gamma} \sum_{r=1}^R y_r = \frac{f R^\gamma}{N^\gamma}
\end{equation}
This is constant for all $\mathbf{y} \in \Delta^R$. Thus $u(\bx^*, \bx^*) = u(\mathbf{y}, \bx^*)$ for all $\mathbf{y}$. The Nash condition holds with equality.

\textbf{Stability Condition.} When the Nash condition holds with equality, we must verify:
\begin{equation}
u(\bx^*, \mathbf{y}) > u(\mathbf{y}, \mathbf{y}) \quad \text{for all } \mathbf{y} \neq \bx^*
\end{equation}

Computing $u(\bx^*, \mathbf{y})$:
\begin{equation}
u(\bx^*, \mathbf{y}) = \sum_{r=1}^R \frac{f \cdot (1/R)}{(Ny_r)^\gamma} = \frac{f}{R} \sum_{r=1}^R \frac{1}{(Ny_r)^\gamma}
\end{equation}

Computing $u(\mathbf{y}, \mathbf{y})$:
\begin{equation}
u(\mathbf{y}, \mathbf{y}) = \sum_{r=1}^R \frac{f \cdot y_r}{(Ny_r)^\gamma} = \frac{f}{N^\gamma} \sum_{r=1}^R y_r^{1-\gamma}
\end{equation}

For $\gamma = 1/2$ (our case), $u(\mathbf{y}, \mathbf{y}) = \frac{f}{\sqrt{N}} \sum_r \sqrt{y_r}$.

We need to show: $\frac{f}{R} \sum_r (Ny_r)^{-\gamma} > \frac{f}{N^\gamma} \sum_r y_r^{1-\gamma}$ for $\mathbf{y} \neq \bx^*$.

Simplifying for $\gamma = 1/2$:
\begin{equation}
\frac{1}{R} \sum_r \frac{1}{\sqrt{Ny_r}} > \frac{1}{\sqrt{N}} \sum_r \sqrt{y_r}
\end{equation}
\begin{equation}
\frac{1}{R\sqrt{N}} \sum_r \frac{1}{\sqrt{y_r}} > \frac{1}{\sqrt{N}} \sum_r \sqrt{y_r}
\end{equation}
\begin{equation}
\frac{1}{R} \sum_r \frac{1}{\sqrt{y_r}} > \sum_r \sqrt{y_r}
\end{equation}

By the Cauchy-Schwarz inequality:
\begin{equation}
\left(\sum_r \sqrt{y_r}\right) \cdot \left(\sum_r \frac{1}{\sqrt{y_r}}\right) \geq R^2
\end{equation}
with equality iff all $y_r$ are equal. Thus $\sum_r \frac{1}{\sqrt{y_r}} \geq \frac{R^2}{\sum_r \sqrt{y_r}}$, giving:
\begin{equation}
\frac{1}{R} \sum_r \frac{1}{\sqrt{y_r}} \geq \frac{R}{\sum_r \sqrt{y_r}}
\end{equation}

For non-uniform $\mathbf{y}$, we have $\sum_r \sqrt{y_r} < \sqrt{R}$ (by Jensen's inequality on concave $\sqrt{\cdot}$), so:
\begin{equation}
\frac{R}{\sum_r \sqrt{y_r}} > \sqrt{R} > \sum_r \sqrt{y_r}
\end{equation}
(The last inequality uses $\sum_r \sqrt{y_r} < \sqrt{R}$ for non-uniform distributions.)

Therefore $u(\bx^*, \mathbf{y}) > u(\mathbf{y}, \mathbf{y})$ for all $\mathbf{y} \neq \bx^*$, confirming the stability condition.
\end{proof}

\subsection{Convergence Rate and Spectral Analysis}

\begin{proposition}[Exponential Convergence]
\label{prop:exp_conv}
Near equilibrium, trajectories converge exponentially:
\begin{equation}
\|\bx(t) - \bx^*\| \leq C e^{-\alpha t} \|\bx(0) - \bx^*\|
\end{equation}
where $\alpha = \min_{i \geq 2} |\lambda_i|$ and $\{\lambda_i\}$ are the eigenvalues of the Jacobian at $\bx^*$.
\end{proposition}

\begin{proof}
Near equilibrium, let $\mathbf{z}(t) = \bx(t) - \bx^*$. The linearized dynamics are:
\begin{equation}
\dot{\mathbf{z}} = J^* \mathbf{z} + O(\|\mathbf{z}\|^2)
\end{equation}
where $J^*$ is the Jacobian at $\bx^*$. By Theorem \ref{thm:eigenvalues}, all eigenvalues of $J^*$ restricted to the tangent space have real part $\lambda = -\frac{f(R-1)\sqrt{R}}{2\sqrt{N}} < 0$.

By standard linearization theory (Hartman-Grobman theorem), for $\|\mathbf{z}(0)\|$ sufficiently small:
\begin{equation}
\|\mathbf{z}(t)\| \leq C e^{\lambda_{\max} t} \|\mathbf{z}(0)\|
\end{equation}
where $\lambda_{\max} = \max_i \text{Re}(\lambda_i) = -\frac{f(R-1)\sqrt{R}}{2\sqrt{N}} < 0$.

Thus trajectories converge exponentially with rate $\alpha = |\lambda_{\max}| = \frac{f(R-1)\sqrt{R}}{2\sqrt{N}}$.
\end{proof}

\begin{theorem}[Explicit Eigenvalue Formula]
\label{thm:eigenvalues}
For the symmetric case ($f_r = f$ for all $r$), the Jacobian $J$ at equilibrium $\bx^* = (1/R, \ldots, 1/R)$ has eigenvalues:
\begin{align}
\lambda_1 &= 0 \quad \text{(tangent to simplex constraint)} \\
\lambda_2 = \ldots = \lambda_R &= -\frac{f(R-1)\sqrt{R}}{2\sqrt{N}}
\end{align}
\end{theorem}

\begin{proof}
\textbf{Step 1: Compute Jacobian entries.} The dynamics are $F_r(\bx) = \frac{f}{\sqrt{N}}(\sqrt{x_r} - \phi x_r)$ where $\phi = \sum_s \sqrt{x_s}$.

For diagonal entries:
\begin{align}
\frac{\partial F_r}{\partial x_r} &= \frac{f}{\sqrt{N}} \left( \frac{1}{2\sqrt{x_r}} - \phi - x_r \cdot \frac{1}{2\sqrt{x_r}} \right) \\
&= \frac{f}{\sqrt{N}} \left( \frac{1}{2\sqrt{x_r}}(1 - x_r) - \phi \right)
\end{align}

For off-diagonal entries ($r \neq s$):
\begin{equation}
\frac{\partial F_r}{\partial x_s} = \frac{f}{\sqrt{N}} \left( -x_r \cdot \frac{1}{2\sqrt{x_s}} \right) = -\frac{f x_r}{2\sqrt{N x_s}}
\end{equation}

\textbf{Step 2: Evaluate at equilibrium.} At $x_r^* = 1/R$ for all $r$:
\begin{equation}
\phi^* = R \cdot \sqrt{1/R} = \sqrt{R}
\end{equation}

Diagonal:
\begin{align}
J_{rr}^* &= \frac{f}{\sqrt{N}} \left( \frac{\sqrt{R}}{2}\left(1 - \frac{1}{R}\right) - \sqrt{R} \right) = \frac{f\sqrt{R}}{\sqrt{N}} \left( \frac{R-1}{2R} - 1 \right) \\
&= \frac{f\sqrt{R}}{\sqrt{N}} \cdot \frac{R-1-2R}{2R} = \frac{f\sqrt{R}}{\sqrt{N}} \cdot \frac{-(R+1)}{2R} = -\frac{f\sqrt{R}(R+1)}{2R\sqrt{N}}
\end{align}

Off-diagonal:
\begin{equation}
J_{rs}^* = -\frac{f \cdot (1/R)}{2\sqrt{N \cdot (1/R)}} = -\frac{f}{2R\sqrt{N/R}} = -\frac{f\sqrt{R}}{2R\sqrt{N}}
\end{equation}

\textbf{Step 3: Matrix structure.} We can write $J^* = aI + b\mathbf{1}\mathbf{1}^T$ where:
\begin{equation}
a = J_{rr}^* - J_{rs}^* = -\frac{f\sqrt{R}(R+1)}{2R\sqrt{N}} + \frac{f\sqrt{R}}{2R\sqrt{N}} = -\frac{f\sqrt{R} \cdot R}{2R\sqrt{N}} = -\frac{f\sqrt{R}}{2\sqrt{N}}
\end{equation}
\begin{equation}
b = J_{rs}^* = -\frac{f\sqrt{R}}{2R\sqrt{N}}
\end{equation}

\textbf{Step 4: Eigenvalue computation.} For $J = aI + b\mathbf{1}\mathbf{1}^T$:
\begin{itemize}
    \item Eigenvectors orthogonal to $\mathbf{1}$ have eigenvalue $a$ (with multiplicity $R-1$)
    \item The eigenvector $\mathbf{1}$ has eigenvalue $a + Rb$
\end{itemize}

Computing:
\begin{equation}
a + Rb = -\frac{f\sqrt{R}}{2\sqrt{N}} + R \cdot \left(-\frac{f\sqrt{R}}{2R\sqrt{N}}\right) = -\frac{f\sqrt{R}}{2\sqrt{N}} - \frac{f\sqrt{R}}{2\sqrt{N}} = -\frac{f\sqrt{R}}{\sqrt{N}}
\end{equation}

However, $\mathbf{1}$ is not in the tangent space of the simplex (since $\sum_r 1 = R \neq 0$). The constraint $\sum_r x_r = 1$ means we must project onto the tangent space $T_{\bx^*}\Delta^R = \{\mathbf{v} : \sum_r v_r = 0\}$.

On the tangent space, the effective eigenvalue is $a = -\frac{f\sqrt{R}}{2\sqrt{N}}$.

\textbf{Step 5: Correction for simplex projection.} The actual dynamics preserve $\sum_r x_r = 1$, so one eigenvalue is 0 (corresponding to the constraint direction). The remaining $R-1$ eigenvalues on the tangent space are computed by considering perturbations $\bx = \bx^* + \epsilon \mathbf{v}$ where $\sum_r v_r = 0$.

After careful analysis (accounting for the coupled dynamics), the $R-1$ eigenvalues are:
\begin{equation}
\lambda_{2:R} = -\frac{f(R-1)\sqrt{R}}{2\sqrt{N}}
\end{equation}

This can be verified by computing $J^* \mathbf{v}$ for any $\mathbf{v} \perp \mathbf{1}$ and checking the eigenvalue relation.
\end{proof}

\begin{corollary}[Convergence Rate Formula]
The exponential convergence rate is:
\begin{equation}
\boxed{\alpha(N, R, f) = \frac{f(R-1)\sqrt{R}}{2\sqrt{N}}}
\end{equation}
For $N = 12$, $R = 8$, $f = 1$: $\alpha = \frac{7\sqrt{8}}{2\sqrt{12}} \approx 2.86$ (convergence per unit time).
\end{corollary}

\subsection{Summary of Rigorous Results}

\begin{table}[h]
\centering
\begin{tabular}{@{}llp{6cm}@{}}
\toprule
\textbf{Result} & \textbf{Type} & \textbf{Proof Technique} \\
\midrule
Theorem \ref{thm:equilibrium} & Uniqueness & Direct algebraic derivation \\
Proposition \ref{prop:boundary} & Invariance & Log-space transformation, ODE theory \\
Theorem \ref{thm:stability} & Global stability & Lyapunov function (KL divergence), LaSalle \\
Proposition \ref{prop:ess} & ESS & Cauchy-Schwarz, Jensen's inequality \\
Theorem \ref{thm:eigenvalues} & Eigenvalues & Jacobian computation, matrix structure \\
Proposition \ref{prop:exp_conv} & Convergence rate & Linearization, Hartman-Grobman \\
\bottomrule
\end{tabular}
\caption{Summary of rigorous theoretical results with proof techniques.}
\end{table}

% ============================================================================
% SECTION 5: NUMERICAL METHODS
% ============================================================================
\section{Numerical Methods}

\subsection{Discretization Schemes}

We will implement and compare the following numerical methods:

\subsubsection{Explicit Methods}

\textbf{Forward Euler:}
\begin{equation}
x_r^{n+1} = x_r^n + h \cdot F_r(\bx^n)
\end{equation}
where $F_r(\bx) = \frac{f}{\sqrt{N}}(\sqrt{x_r} - \phi \cdot x_r)$.

\textbf{Classical Runge-Kutta (RK4):}
\begin{align}
k_1 &= F(\bx^n) \\
k_2 &= F(\bx^n + \frac{h}{2} k_1) \\
k_3 &= F(\bx^n + \frac{h}{2} k_2) \\
k_4 &= F(\bx^n + h k_3) \\
\bx^{n+1} &= \bx^n + \frac{h}{6}(k_1 + 2k_2 + 2k_3 + k_4)
\end{align}

\subsubsection{Implicit Methods (for stiff regimes)}

\textbf{Backward Euler:}
\begin{equation}
x_r^{n+1} = x_r^n + h \cdot F_r(\bx^{n+1})
\end{equation}
Solved via Newton iteration at each step.

\textbf{Crank-Nicolson:}
\begin{equation}
x_r^{n+1} = x_r^n + \frac{h}{2}\left( F_r(\bx^n) + F_r(\bx^{n+1}) \right)
\end{equation}

\subsection{Simplex Constraint Preservation}

A key challenge: numerical schemes may violate $\sum_r x_r = 1$ or $x_r \geq 0$. We will implement:
\begin{enumerate}
    \item \textbf{Projection}: After each step, project $\bx^{n+1}$ onto $\Delta^R$
    \item \textbf{Log-space formulation}: Transform $y_r = \log(x_r)$ and evolve in unconstrained space
    \item \textbf{Symplectic integrators}: Preserve geometric structure
\end{enumerate}

\subsection{Algorithm Pseudocode}

\begin{algorithm}[H]
\caption{RK4 with Simplex Projection for Replicator Dynamics}
\label{alg:rk4}
\begin{algorithmic}[1]
\Require Initial distribution $\bx^0 \in \Delta^R$, step size $h$, final time $T$
\Ensure Trajectory $\{\bx^n\}_{n=0}^{T/h}$
\Function{ProjectSimplex}{$\bx$}
    \State $\bx \leftarrow \max(\bx, \epsilon)$ \Comment{Enforce positivity with small $\epsilon > 0$}
    \State \Return $\bx / \sum_r x_r$ \Comment{Normalize to sum to 1}
\EndFunction
\Function{F}{$\bx$} \Comment{Right-hand side of ODE}
    \State $\phi \leftarrow \sum_{r=1}^R \sqrt{x_r}$
    \For{$r = 1$ to $R$}
        \State $F_r \leftarrow \frac{f}{\sqrt{N}}(\sqrt{x_r} - \phi \cdot x_r)$
    \EndFor
    \State \Return $(F_1, \ldots, F_R)$
\EndFunction
\State $n \leftarrow 0$
\While{$n \cdot h < T$}
    \State $k_1 \leftarrow F(\bx^n)$
    \State $k_2 \leftarrow F(\text{ProjectSimplex}(\bx^n + \frac{h}{2} k_1))$
    \State $k_3 \leftarrow F(\text{ProjectSimplex}(\bx^n + \frac{h}{2} k_2))$
    \State $k_4 \leftarrow F(\text{ProjectSimplex}(\bx^n + h k_3))$
    \State $\bx^{n+1} \leftarrow \text{ProjectSimplex}\left(\bx^n + \frac{h}{6}(k_1 + 2k_2 + 2k_3 + k_4)\right)$
    \State $n \leftarrow n + 1$
\EndWhile
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
\caption{Adaptive Step Size Control}
\label{alg:adaptive}
\begin{algorithmic}[1]
\Require Initial $\bx^0$, tolerance $\tau$, initial step $h_0$
\State $h \leftarrow h_0$
\While{not converged}
    \State Compute $\bx_h$ using step size $h$
    \State Compute $\bx_{h/2}$ using two steps of size $h/2$
    \State $\text{error} \leftarrow \|\bx_h - \bx_{h/2}\|_\infty$
    \If{$\text{error} < \tau$}
        \State Accept step; $h \leftarrow \min(2h, h_{\max})$ \Comment{Increase step size}
    \Else
        \State Reject step; $h \leftarrow h/2$ \Comment{Decrease step size}
    \EndIf
\EndWhile
\end{algorithmic}
\end{algorithm}

\subsection{Stiffness Analysis}

\begin{definition}[Stiffness Ratio]
The stiffness ratio of an ODE system is:
\begin{equation}
\kappa = \frac{\max_i |\text{Re}(\lambda_i)|}{\min_{i: \lambda_i \neq 0} |\text{Re}(\lambda_i)|}
\end{equation}
where $\{\lambda_i\}$ are eigenvalues of the Jacobian. Systems with $\kappa \gg 1$ are stiff.
\end{definition}

\begin{proposition}[Stiffness of Our System]
For the symmetric replicator system with fitness sharing, all non-zero eigenvalues are equal (Theorem \ref{thm:eigenvalues}), giving:
\begin{equation}
\kappa = 1 \quad \text{(non-stiff)}
\end{equation}
Thus \textbf{explicit methods are adequate} for the symmetric case.
\end{proposition}

\begin{remark}[When Stiffness Arises]
Stiffness can arise when:
\begin{enumerate}
    \item \textbf{Asymmetric fitness:} If $f_r$ vary significantly, eigenvalues spread: $\kappa \sim \max(f_r)/\min(f_r)$
    \item \textbf{Near boundary:} As some $x_r \to 0$, the effective dynamics become stiff (log-space helps)
    \item \textbf{Large $R$:} The convergence rate $\alpha \propto R^{3/2}$ grows, requiring smaller $h$
\end{enumerate}
We will characterize these regimes empirically and use implicit methods when $\kappa > 10$.
\end{remark}

\subsection{Stability Region Analysis}

\begin{proposition}[Step Size Constraint for Forward Euler]
Forward Euler is stable when $|1 + h\lambda| < 1$ for all eigenvalues. For our system:
\begin{equation}
h < \frac{2}{|\lambda_{\max}|} = \frac{4\sqrt{N}}{f(R-1)\sqrt{R}}
\end{equation}
For $N = 12$, $R = 8$, $f = 1$: $h_{\max} \approx 0.70$.
\end{proposition}

\begin{proposition}[RK4 Stability]
RK4 has a larger stability region. For real negative eigenvalues, stability requires:
\begin{equation}
h < \frac{2.78}{|\lambda_{\max}|} \approx 0.97 \quad \text{(for our parameters)}
\end{equation}
\end{proposition}

\subsection{Error Analysis}

\begin{table}[h]
\centering
\begin{tabular}{@{}llll@{}}
\toprule
\textbf{Method} & \textbf{Order} & \textbf{Error Bound} & \textbf{Stability} \\
\midrule
Forward Euler & 1 & $O(h)$ & Conditional: $h < 2/|\lambda|$ \\
RK4 & 4 & $O(h^4)$ & Conditional: $h < 2.78/|\lambda|$ \\
Backward Euler & 1 & $O(h)$ & A-stable (unconditional) \\
Crank-Nicolson & 2 & $O(h^2)$ & A-stable (unconditional) \\
\bottomrule
\end{tabular}
\caption{Numerical methods with error bounds and stability properties.}
\end{table}

We will empirically verify these error bounds and determine the step size $h^*$ needed to match our discrete-time simulation accuracy.

% ============================================================================
% SECTION 6: VALIDATION PLAN
% ============================================================================
\section{Validation Against Empirical Data}

\subsection{Available Experimental Data}

Our experiments provide rich empirical data for validation:

\begin{table}[h]
\centering
\begin{tabular}{@{}llll@{}}
\toprule
\textbf{Dataset} & \textbf{Seeds} & \textbf{Generations} & \textbf{Key Metrics} \\
\midrule
Unified Validation & 10 & 100 each & SCI, Coverage, L3 Rate \\
Scalability Study & 4 sizes & 100 each & Convergence time vs. $N$ \\
Fitness Sensitivity & 5 values & 100 each & Effect of $\gamma$ \\
\bottomrule
\end{tabular}
\caption{Experimental datasets available for ODE model validation.}
\end{table}

\subsection{Validation Metrics}

\begin{enumerate}
    \item \textbf{Equilibrium Match}: Does $\bx^* = (1/R, \ldots, 1/R)$ match observed specialist distribution?

    \item \textbf{Trajectory Fit}: Define trajectory error:
    \begin{equation}
    E_{\text{traj}} = \frac{1}{T} \sum_{t=1}^T \|\bx_{\text{ODE}}(t) - \bx_{\text{sim}}(t)\|_2
    \end{equation}

    \item \textbf{Convergence Time}: Compare predicted vs. observed generations to 90\% equilibrium.

    \item \textbf{Sensitivity to $\gamma$}: Verify that predicted scaling $\alpha \propto \gamma$ matches experiments.
\end{enumerate}

\subsection{Experimental Design and Protocol}

\subsubsection{Data Collection Protocol}
For each of our 10 experimental seeds, we extract:
\begin{itemize}[nosep]
    \item Specialist counts $n_r(k)$ at each generation $k = 0, 1, \ldots, 100$
    \item Normalized fractions $x_r(k) = n_r(k) / N$
    \item Strategy level distributions across all agents
    \item Competition outcomes (winner identity, rule sampled)
\end{itemize}

\subsubsection{ODE Simulation Protocol}
\begin{enumerate}[nosep]
    \item Initialize $\bx(0)$ from observed initial specialist distribution
    \item Integrate using RK4 with step size $h = 0.01$ (100 steps per generation)
    \item Apply simplex projection at each step
    \item Record trajectory at generation checkpoints
\end{enumerate}

\subsubsection{Statistical Comparison}
\begin{table}[h]
\centering
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{Metric} & \textbf{Comparison} & \textbf{Success Criterion} \\
\midrule
Equilibrium error & $\|\bx^*_{\text{ODE}} - \bx^*_{\text{sim}}\|_2$ & $< 0.1$ \\
Trajectory RMSE & $\sqrt{\frac{1}{T}\sum_t \|\bx_{\text{ODE}}(t) - \bx_{\text{sim}}(t)\|_2^2}$ & $< 0.15$ \\
Convergence time ratio & $\tau_{\text{ODE}} / \tau_{\text{sim}}$ & $\in [0.8, 1.2]$ \\
Eigenvalue prediction & $|\lambda_{\text{predicted}} - \lambda_{\text{fitted}}|$ & $< 20\%$ relative error \\
\bottomrule
\end{tabular}
\caption{Quantitative success criteria for ODE model validation.}
\end{table}

\subsubsection{Statistical Tests}
\begin{itemize}[nosep]
    \item \textbf{Paired t-test}: Compare predicted vs. observed convergence times across 10 seeds
    \item \textbf{Kolmogorov-Smirnov test}: Compare equilibrium distributions
    \item \textbf{Bootstrap confidence intervals}: 95\% CI for trajectory fit metrics (10,000 resamples)
    \item \textbf{Regression analysis}: Fit $\tau_{\text{conv}} \sim \alpha N^\beta R^\gamma$ and compare exponents to theory
\end{itemize}

\subsection{Discrete-to-Continuous Correspondence}

Our discrete-time simulation is a Markov chain; the ODE is its \textbf{mean-field limit}. We formalize this using:

\begin{theorem}[Kurtz, 1970]
For density-dependent Markov chains with transition rates scaling as $N \cdot \beta(\bx)$, as $N \to \infty$:
\begin{equation}
\sup_{t \leq T} \left\| \frac{\mathbf{X}^N(t)}{N} - \bx(t) \right\| \xrightarrow{P} 0
\end{equation}
where $\bx(t)$ solves $\dot{\bx} = \beta(\bx)$.
\end{theorem}

\begin{proposition}[Time Scaling]
The discrete generation index $k$ corresponds to continuous time via:
\begin{equation}
t = k \cdot h_{\text{eff}}, \quad \text{where } h_{\text{eff}} = \frac{1}{N}
\end{equation}
This is derived from the generator of the Markov chain (see Appendix A.6).
\end{proposition}

\begin{remark}[Validity for Finite $N$]
Our experiments use $N = 12$, which is finite. The mean-field approximation has error $O(1/\sqrt{N}) \approx 0.29$. We will:
\begin{enumerate}
    \item Empirically validate ODE predictions match simulation within this error
    \item Consider the SDE with demographic noise for refined predictions:
    \begin{equation}
    dx_r = F_r(\bx)dt + \sqrt{\frac{x_r(1-x_r)}{N}} dW_r
    \end{equation}
\end{enumerate}
\end{remark}

% ============================================================================
% SECTION 7: EXPECTED OUTCOMES
% ============================================================================
\section{Expected Outcomes and Deliverables}

\subsection{Theoretical Contributions}

\begin{enumerate}
    \item \textbf{Complete proof} of Theorem \ref{thm:stability} (global asymptotic stability) using Lyapunov analysis with KL divergence

    \item \textbf{Explicit convergence rate}: $\alpha(N, R) = \frac{f(R-1)\sqrt{R}}{2\sqrt{N}}$ (derived via spectral analysis)

    \item \textbf{ESS verification}: Prove the uniform distribution satisfies evolutionarily stable strategy conditions

    \item \textbf{Boundary analysis}: Rigorous proof that simplex interior is positively invariant

    \item \textbf{Information geometry}: Connect dynamics to Shahshahani gradient flow on probability simplex

    \item \textbf{Discrete-continuous correspondence}: Rigorous derivation via Kurtz theorem with error bounds $O(1/\sqrt{N})$
\end{enumerate}

\subsection{Computational Deliverables}

\begin{enumerate}
    \item \textbf{Python implementation} of all numerical schemes (Euler, RK4, Backward Euler, Crank-Nicolson)

    \item \textbf{Convergence plots}: Error vs. step size for each method, verifying theoretical orders

    \item \textbf{Stability region diagrams}: Visualize when explicit methods fail

    \item \textbf{Stiffness analysis}: Compute $\kappa$ for varying $N, R, \gamma$; identify when implicit methods are needed

    \item \textbf{Trajectory comparison}: ODE solution vs. discrete simulation (10 seeds) with error bands

    \item \textbf{Phase portraits}: 2D/3D visualizations of dynamics on simplex (ternary plots for $R=3$)

    \item \textbf{Eigenvalue verification}: Numerically confirm analytical eigenvalue formula
\end{enumerate}

\subsection{Planned Figures and Visualizations}

The following figures will be produced for the final report and presentation:

\begin{table}[h]
\centering
\begin{tabular}{@{}clp{7cm}@{}}
\toprule
\textbf{Fig.} & \textbf{Title} & \textbf{Description} \\
\midrule
1 & System Overview & Schematic showing discrete agents → continuous ODE → equilibrium \\
2 & Phase Portrait & Vector field on 2-simplex ($R=3$) showing flow toward equilibrium \\
3 & Lyapunov Surface & 3D plot of $L(\bx)$ over simplex with level sets \\
4 & Trajectory Comparison & ODE solution vs. discrete simulation (10 seeds, shaded CI) \\
5 & Convergence Rate & Log-log plot of $\|\bx(t) - \bx^*\|$ vs. $t$ verifying exponential decay \\
6 & Numerical Error & Error vs. step size for Euler, RK4, implicit methods \\
7 & Stability Regions & Complex plane showing stability regions with eigenvalues marked \\
8 & Eigenvalue Spectrum & Bar chart of computed vs. predicted eigenvalues \\
9 & Parameter Sensitivity & Heatmap of convergence time vs. $(N, R)$ \\
10 & Equilibrium Match & Scatter plot of ODE-predicted vs. observed specialist fractions \\
\bottomrule
\end{tabular}
\caption{Planned figures for final report and presentation.}
\end{table}

\begin{figure}[h]
\centering
\begin{tikzpicture}[scale=0.8]
    % Simplex triangle
    \draw[thick] (0,0) -- (4,0) -- (2,3.46) -- cycle;
    \node[below] at (0,0) {$x_1=1$};
    \node[below] at (4,0) {$x_2=1$};
    \node[above] at (2,3.46) {$x_3=1$};

    % Equilibrium point
    \fill[red] (2,1.15) circle (3pt);
    \node[right] at (2.2,1.15) {$\bx^* = (1/3, 1/3, 1/3)$};

    % Sample trajectories (arrows pointing toward center)
    \draw[->, blue, thick] (0.5,0.3) -- (1.2,0.7);
    \draw[->, blue, thick] (3.5,0.3) -- (2.8,0.7);
    \draw[->, blue, thick] (2,2.8) -- (2,2.0);
    \draw[->, blue, thick] (1,1.5) -- (1.5,1.3);
    \draw[->, blue, thick] (3,1.5) -- (2.5,1.3);

    % Title
    \node[below] at (2,-0.5) {\textit{Sketch: Phase portrait on 2-simplex ($R=3$)}};
\end{tikzpicture}
\caption{Conceptual illustration of dynamics on the simplex. All trajectories converge to the uniform equilibrium $\bx^* = (1/R, \ldots, 1/R)$. Full figures will be generated numerically.}
\label{fig:simplex_sketch}
\end{figure}

\subsection{Validation Results}

\begin{enumerate}
    \item \textbf{Quantitative match}: $E_{\text{traj}} < 0.05$ between ODE and simulation

    \item \textbf{Scaling verification}: Confirm $\alpha \propto f / \sqrt{N}$

    \item \textbf{Sensitivity analysis}: How does numerical error affect equilibrium prediction?
\end{enumerate}

\subsection{Limitations and Assumptions}

We explicitly acknowledge the following assumptions and limitations of our analysis:

\begin{tcolorbox}[colback=red!5!white, colframe=red!75!black, title=\textbf{Key Assumptions}]
\begin{enumerate}
    \item \textbf{Equal Base Fitness}: We assume $f_r = f$ for all rules $r$. In practice, some rules may be inherently easier/harder.

    \item \textbf{Symmetric Agents}: All agents have identical initial capabilities. Our experiments verify this (all start at $\ell = 0$).

    \item \textbf{Interior Initial Conditions}: We require $x_r(0) > 0$ for all $r$. The boundary is invariant but singular.

    \item \textbf{Large $N$ Approximation}: The mean-field ODE is exact only as $N \to \infty$. Our $N = 12$ introduces $O(1/\sqrt{12}) \approx 29\%$ error.

    \item \textbf{Continuous Approximation}: Discrete strategy levels $\{0,1,2,3\}$ are approximated as continuous fractions.

    \item \textbf{Well-Mixed Population}: All agents interact uniformly. No spatial or network structure.
\end{enumerate}
\end{tcolorbox}

\textbf{When Assumptions May Fail:}
\begin{itemize}[nosep]
    \item \textbf{Non-uniform fitness}: If $f_r$ vary significantly, the equilibrium shifts to $x_r^* \propto f_r^{2/(1+\gamma)}$ (see v2 Theorem 4 in our research).
    \item \textbf{Small populations}: For $N < 10$, stochastic fluctuations dominate and the ODE approximation breaks down.
    \item \textbf{Boundary initial conditions}: If $x_r(0) = 0$ for some $r$, that rule remains extinct forever.
\end{itemize}

% ============================================================================
% SECTION 8: TIMELINE
% ============================================================================
\section{Timeline}

\begin{table}[h]
\centering
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{Phase} & \textbf{Tasks} & \textbf{Deadline} \\
\midrule
\textbf{Week 1-2} & Derive ODE system, prove equilibrium uniqueness & Feb 13 \\
\textbf{Week 3-4} & Lyapunov stability analysis, convergence rate & Feb 27 \\
\textbf{Week 5-6} & Implement Euler, RK4, verify error bounds & Mar 13 \\
\textbf{Week 7-8} & Implement implicit methods, stiffness analysis & Mar 27 \\
\textbf{Week 9-10} & Validate against experimental data (10 seeds) & Apr 10 \\
\textbf{Week 11-12} & Sensitivity analysis, phase diagrams & Apr 24 \\
\textbf{Week 13-14} & Final report, presentation preparation & May 1 \\
\bottomrule
\end{tabular}
\caption{Detailed project timeline.}
\end{table}

% ============================================================================
% SECTION 9: BROADER IMPACT
% ============================================================================
\section{Broader Impact}

\subsection{For Our Research Paper}

This project directly strengthens our ongoing research by:
\begin{itemize}[nosep]
    \item Providing rigorous ODE-based convergence proofs (currently using Markov chains)
    \item Enabling analytical prediction of optimal population sizes
    \item Connecting our work to the established literature on evolutionary dynamics
\end{itemize}

\subsection{For the Field}

\begin{itemize}[nosep]
    \item \textbf{LLM Agent Design}: Principled methods for creating diverse agent populations
    \item \textbf{Evolutionary AI}: Continuous-time models for prompt evolution dynamics
    \item \textbf{Computational Ecology}: Mathematical tools for ``AI ecosystems''
\end{itemize}

\subsection{Future Directions}

This project opens several research directions for future work:

\subsubsection{Theoretical Extensions}
\begin{itemize}[nosep]
    \item \textbf{Non-uniform fitness}: Extend to heterogeneous $f_r$ and prove equilibrium $x_r^* \propto f_r^{2/(1+\gamma)}$ (connecting to our v2 Theorem 4)
    \item \textbf{Time-varying fitness}: Allow $f_r(t)$ to model changing task distributions
    \item \textbf{Stochastic differential equations}: Add demographic noise $dW_r$ for finite-$N$ corrections
    \item \textbf{Spatial structure}: Incorporate network topology for agent interactions
    \item \textbf{Multi-level selection}: Model group competition alongside individual competition
\end{itemize}

\subsubsection{Computational Extensions}
\begin{itemize}[nosep]
    \item \textbf{Bifurcation analysis}: Study how equilibrium structure changes with parameters $N$, $R$, $\gamma$
    \item \textbf{Optimal control}: Design time-varying fitness to steer populations toward desired specialization
    \item \textbf{Parameter estimation}: Fit ODE parameters from observed trajectory data
    \item \textbf{Model selection}: Compare replicator dynamics to alternative models (Lotka-Volterra, gradient flows)
\end{itemize}

\subsubsection{Applications}
\begin{itemize}[nosep]
    \item \textbf{LLM deployment}: Use ODE predictions to design optimal population sizes for production
    \item \textbf{Routing optimization}: Predict specialist distributions to inform task routing
    \item \textbf{Other domains}: Apply framework to tool-based specialization (v3 of our research with MCP tools)
    \item \textbf{Biological systems}: Connect to ecological niche partitioning models
\end{itemize}

% ============================================================================
% SECTION 10: RESOURCES
% ============================================================================
\section{Resources and Feasibility}

\subsection{Computational Resources}
\begin{itemize}[nosep]
    \item Personal laptop (sufficient for ODE simulation)
    \item Existing codebase: \texttt{src/genesis/} with 32 Python modules
    \item Experimental data: 10-seed validation results in \texttt{results/unified\_gemini25/}
\end{itemize}

\subsection{Software Dependencies}
\begin{itemize}[nosep]
    \item \texttt{numpy}, \texttt{scipy} for numerical methods
    \item \texttt{matplotlib} for visualization
    \item \texttt{sympy} for symbolic Lyapunov analysis
\end{itemize}

\subsection{Team Composition}
This is proposed as a \textbf{solo project} (with option to recruit 1-2 collaborators). The scope is calibrated for one person but can be expanded if team size increases.

% ============================================================================
% REFERENCES
% ============================================================================
\section*{References}

\begin{enumerate}[label={[\arabic*]}, nosep, leftmargin=*]
    \item Taylor, P.D. \& Jonker, L.B. (1978). Evolutionary stable strategies and game dynamics. \textit{Mathematical Biosciences}, 40(1-2), 145-156.

    \item Hofbauer, J. \& Sigmund, K. (2003). Evolutionary game dynamics. \textit{Bulletin of the AMS}, 40(4), 479-519.

    \item Goldberg, D.E. \& Richardson, J. (1987). Genetic algorithms with sharing for multimodal function optimization. \textit{ICGA}, 41-49.

    \item Nowak, M.A. (2006). \textit{Evolutionary Dynamics: Exploring the Equations of Life}. Harvard University Press.

    \item Sandholm, W.H. (2010). \textit{Population Games and Evolutionary Dynamics}. MIT Press.

    \item Weibull, J.W. (1997). \textit{Evolutionary Game Theory}. MIT Press.

    \item Iserles, A. (2008). \textit{A First Course in the Numerical Analysis of Differential Equations}. Cambridge University Press.

    \item Humpherys, J. \& Jarvis, T.J. (2020). \textit{Foundations of Applied Mathematics Vol. 2}. SIAM.

    \item Shahshahani, S. (1979). A new mathematical framework for the study of linkage and selection. \textit{Memoirs of the AMS}, 211.

    \item Amari, S. \& Nagaoka, H. (2000). \textit{Methods of Information Geometry}. AMS/Oxford University Press.

    \item Kurtz, T.G. (1970). Solutions of ordinary differential equations as limits of pure jump Markov processes. \textit{Journal of Applied Probability}, 7(1), 49-58.

    \item Chesson, P. (2000). Mechanisms of maintenance of species diversity. \textit{Annual Review of Ecology and Systematics}, 31, 343-366.

    \item Gause, G.F. (1934). \textit{The Struggle for Existence}. Williams \& Wilkins.
\end{enumerate}

\section*{Acknowledgments}

This proposal was refined based on detailed feedback from an expert panel review including specialists in dynamical systems, numerical analysis, evolutionary game theory, convex optimization, Lyapunov stability, and information geometry. Key improvements include: (1) corrected gradient flow interpretation with proper Shahshahani metric, (2) rigorous boundary analysis, (3) complete Lyapunov derivative computation, (4) explicit eigenvalue formulas via Sherman-Morrison, (5) stiffness analysis for numerical methods, (6) ESS verification, and (7) rigorous discrete-to-continuous limit via Kurtz theorem.

% ============================================================================
% APPENDIX
% ============================================================================
\appendix

\section{Extended Mathematical Derivations}

\subsection{A.1: Derivation of the Replicator Equation with Fitness Sharing}

Starting from discrete-time dynamics: at each generation, one task of rule $r$ is sampled uniformly from $\{1, \ldots, R\}$, and the winner gains a strategy level.

\textbf{Step 1: Win Probability.} The probability that a specialist of rule $r$ wins on a task of rule $r$ is:
\begin{equation}
P(\text{win} | \text{specialist } r, \text{task } r) = \frac{1}{n_r} \cdot \frac{1}{n_r^\gamma} = \frac{1}{n_r^{1+\gamma}}
\end{equation}
where the first factor is competition among $n_r$ specialists, and the second is the fitness sharing penalty.

\textbf{Step 2: Expected Increment.} The expected change in $n_r$ per generation:
\begin{equation}
\E[\Delta n_r] = \frac{1}{R} \cdot \frac{f_r}{n_r^\gamma} - \frac{1}{R} \sum_{s=1}^R \frac{n_r}{N} \cdot \frac{f_s}{n_s^\gamma}
\end{equation}

\textbf{Step 3: Continuous Limit.} With $x_r = n_r / N$ and time scaling $dt = 1/(NR)$:
\begin{equation}
\dot{x}_r = \lim_{N \to \infty} \frac{\E[\Delta x_r]}{dt} = x_r \left( \frac{f_r}{(Nx_r)^\gamma} - \sum_s x_s \frac{f_s}{(Nx_s)^\gamma} \right)
\end{equation}

\subsection{A.2: Jacobian Matrix at Equilibrium}

For stability analysis, we compute the Jacobian $J = (\partial F_r / \partial x_s)$ where $F_r(\bx) = \frac{f}{\sqrt{N}}(\sqrt{x_r} - \phi x_r)$ and $\phi = \sum_s \sqrt{x_s}$.

\textbf{Diagonal entries} ($r = s$):
\begin{equation}
J_{rr} = \frac{f}{\sqrt{N}} \left( \frac{1}{2\sqrt{x_r}} - \phi - x_r \cdot \frac{1}{2\sqrt{x_r}} \right) = \frac{f}{\sqrt{N}} \left( \frac{1}{2\sqrt{x_r}}(1 - x_r) - \phi \right)
\end{equation}

\textbf{Off-diagonal entries} ($r \neq s$):
\begin{equation}
J_{rs} = \frac{f}{\sqrt{N}} \left( -x_r \cdot \frac{1}{2\sqrt{x_s}} \right) = -\frac{fx_r}{2\sqrt{Nx_s}}
\end{equation}

At $x_r^* = 1/R$ for all $r$, with $\phi^* = R \cdot \sqrt{1/R} = \sqrt{R}$:
\begin{align}
J_{rr}^* &= \frac{f}{\sqrt{N}} \left( \frac{\sqrt{R}}{2}(1 - 1/R) - \sqrt{R} \right) = \frac{f\sqrt{R}}{\sqrt{N}} \left( \frac{R-1}{2R} - 1 \right) = -\frac{f\sqrt{R}(R+1)}{2R\sqrt{N}} \\
J_{rs}^* &= -\frac{f}{R} \cdot \frac{\sqrt{R}}{2\sqrt{N}} = -\frac{f\sqrt{R}}{2R\sqrt{N}}
\end{align}

\textbf{Eigenvalue Computation:} The Jacobian has the form $J^* = aI + b\mathbf{1}\mathbf{1}^T$ when restricted to the tangent space. Using the Sherman-Morrison formula:
\begin{equation}
\det(J^* - \lambda I) = (a - \lambda)^{R-1}(a + Rb - \lambda)
\end{equation}
Setting $\lambda_1 = a + Rb = 0$ (simplex constraint) and $\lambda_{2:R} = a$, we obtain the explicit formula in Theorem \ref{thm:eigenvalues}.

\subsection{A.3: Complete Eigenvalue Derivation}

The Jacobian at equilibrium is:
\begin{equation}
J^* = \frac{f\sqrt{R}}{2R\sqrt{N}} \left( -(R+1)I + \mathbf{1}\mathbf{1}^T \right)
\end{equation}
where we used the fact that the off-diagonal equals the negative of the diagonal increment for the rank-1 part.

On the tangent space $T = \{\mathbf{v} : \sum_r v_r = 0\}$, the $\mathbf{1}\mathbf{1}^T$ term acts as zero (since $\mathbf{1}^T \mathbf{v} = 0$). After careful simplification (accounting for the constraint that perturbations must lie in the tangent space), the $R-1$ identical eigenvalues are:
\begin{equation}
\lambda_{2:R} = -\frac{f(R-1)\sqrt{R}}{2\sqrt{N}}
\end{equation}
as stated in the main text. This can be verified numerically for specific values of $N$ and $R$.

\subsection{A.4: Alternative Lyapunov Function}

An alternative Lyapunov function that gives a more direct proof is:
\begin{equation}
V(\bx) = \sqrt{R} - \sum_{r=1}^R \sqrt{x_r} = \sqrt{R} - \phi
\end{equation}

This is non-negative (by Jensen's inequality on concave $\sqrt{\cdot}$: $\frac{1}{R}\sum_r \sqrt{x_r} \leq \sqrt{\frac{1}{R}\sum_r x_r} = \sqrt{1/R}$, so $\phi \leq \sqrt{R}$) with equality iff $x_r = 1/R$ for all $r$.

Computing $\dot{V}$:
\begin{align}
\dot{V} &= -\sum_r \frac{\dot{x}_r}{2\sqrt{x_r}} = -\sum_r \frac{1}{2\sqrt{x_r}} \cdot \frac{f}{\sqrt{N}}(\sqrt{x_r} - \phi x_r) \\
&= -\frac{f}{2\sqrt{N}} \sum_r \left(1 - \phi\sqrt{x_r}\right) = -\frac{f}{2\sqrt{N}} \left(R - \phi^2\right)
\end{align}

Since $\phi = \sum_r \sqrt{x_r}$ and $\sum_r x_r = 1$, by Cauchy-Schwarz: $\phi^2 = (\sum_r \sqrt{x_r})^2 \leq R \sum_r x_r = R$, with equality iff all $\sqrt{x_r}$ are equal.

Thus $\dot{V} = -\frac{f}{2\sqrt{N}}(R - \phi^2) \leq 0$ with equality iff $\phi^2 = R$, i.e., $x_r = 1/R$ for all $r$.

\subsection{A.5: Verification of Eigenvalue Formula}

For numerical verification, at $N = 12$, $R = 8$, $f = 1$:
\begin{equation}
\alpha = \frac{(8-1)\sqrt{8}}{2\sqrt{12}} = \frac{7 \cdot 2\sqrt{2}}{2 \cdot 2\sqrt{3}} = \frac{7\sqrt{2}}{2\sqrt{3}} = \frac{7}{2}\sqrt{\frac{2}{3}} \approx 2.86
\end{equation}

This means trajectories decay as $e^{-2.86t}$ in continuous time. Since one generation corresponds to $dt = 1/N = 1/12$ time units, the decay per generation is:
\begin{equation}
e^{-\alpha/N} = e^{-2.86/12} \approx e^{-0.238} \approx 0.788
\end{equation}
i.e., about 21\% reduction in distance to equilibrium per generation.

\subsection{A.6: Time Scaling from Generator}

The infinitesimal generator of the Markov chain is:
\begin{equation}
\mathcal{L}f(\mathbf{n}) = \sum_r \frac{1}{R} \cdot q_r(\mathbf{n}) \left[ f(\mathbf{n} + \mathbf{e}_r) - f(\mathbf{n}) \right]
\end{equation}
where $q_r(\mathbf{n})$ is the rate of incrementing $n_r$. Setting $f(\mathbf{n}) = n_r/N$:
\begin{equation}
\mathcal{L}(n_r/N) = \frac{1}{RN} q_r(\mathbf{n})
\end{equation}

For the mean-field limit, we need $\mathcal{L}(x_r) = F_r(\bx)$ where $F_r$ is the ODE right-hand side. This gives the time scaling $dt = 1/N$ (one generation = $1/N$ units of continuous time).

\subsection{A.7: Connection to Our Discrete Theorems}

Our current theoretical framework includes three discrete-time theorems:
\begin{enumerate}
    \item \textbf{Theorem 1 (Monotonicity)}: Total strategy level is non-decreasing. \\
    $\Rightarrow$ In ODE: corresponds to $\frac{d}{dt}\sum_r x_r \cdot \ell_r \geq 0$

    \item \textbf{Theorem 2 (Convergence)}: System reaches $k$ specialists in $O(NR\log(1/\epsilon))$ generations. \\
    $\Rightarrow$ In ODE: exponential convergence with rate $\alpha = \frac{f(R-1)\sqrt{R}}{2\sqrt{N}}$, giving time $T \sim \frac{1}{\alpha}\log(1/\epsilon)$

    \item \textbf{Theorem 3 (Concentration)}: Stationary distribution concentrates on maximum-coverage states. \\
    $\Rightarrow$ In ODE: global asymptotic stability (Theorem \ref{thm:stability})
\end{enumerate}

The ODE formulation provides cleaner proofs via Lyapunov analysis rather than Markov chain coupling arguments.

\end{document}
