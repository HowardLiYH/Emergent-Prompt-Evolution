% =============================================================================
% EMERGENT PREFERENCE SPECIALIZATION IN LLM AGENT POPULATIONS
% NeurIPS 2025 Submission
% =============================================================================
% Main body: 10 pages max (excluding references and appendix)
% Appendix: Unlimited
% =============================================================================

\documentclass[11pt]{article}

% NeurIPS 2025 style
\usepackage[final]{neurips_2025}

% Essential packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{url}
\usepackage{booktabs}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{nicefrac}
\usepackage{microtype}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{amsthm}
\usepackage{multirow}
\usepackage{enumitem}

% Theorem environments
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}{Definition}

% Custom commands
\newcommand{\R}{\mathbb{R}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\Var}{\text{Var}}

% =============================================================================
% TITLE AND AUTHORS
% =============================================================================
\title{Emergent Preference Specialization in LLM Agent Populations\\Through Competitive Selection}

\author{
  Yuhao Li \\
  University of Pennsylvania\\
  \texttt{li88@sas.upenn.edu}
}

\begin{document}

\maketitle

% =============================================================================
% ABSTRACT
% =============================================================================
\begin{abstract}
We discover and theoretically characterize a novel emergent phenomenon: populations of initially identical LLM agents spontaneously develop \textit{specialized preferences} through competitive selection alone---without gradient-based training or explicit diversity incentives. Using controlled experiments with 8 synthetic rule domains (designed to preclude prior knowledge), we demonstrate that competitive dynamics drive niche differentiation with \textbf{70.7\% causality validation} (Cohen's $d=2.66$, $n=10$ seeds). \textbf{Remarkably, ablation studies reveal that competition alone produces 94\% of the observed specialization} (SCI=0.773 vs 0.818 full system), proving that diversity genuinely \textit{emerges} rather than being engineered. We provide three proven theorems establishing convergence guarantees via Markov chain analysis. Evolved specialists achieve the \textbf{theoretical ceiling (100\% accuracy)} on matched tasks, with oracle routing unlocking \textbf{+64.2\% improvement} over generalists (95\% CI: [61.3, 67.0]). \textbf{Critically, this demonstrates that prompt-based specialization achieves the same performance ceiling as fine-tuning---but at zero cost, with instant deployment, and full reversibility.} Our findings establish prompt-based specialization as a viable paradigm and reveal fundamental principles connecting LLM population dynamics to ecological niche theory.
\end{abstract}

% =============================================================================
% SECTION 1: INTRODUCTION
% =============================================================================
\section{Introduction}
\label{sec:intro}

Large language models (LLMs) exhibit remarkable general capabilities, yet many applications would benefit from \textit{specialized} agents. The dominant paradigm for specialization---fine-tuning---requires gradient access, substantial compute, and risks catastrophic forgetting~\cite{kirkpatrick2017ewc}. This raises a fundamental scientific question: \textbf{Can specialization emerge spontaneously from competitive dynamics, without explicit design or gradient-based training?}

We answer affirmatively, demonstrating a novel emergent phenomenon. When populations of identical LLM agents compete for limited ``wins,'' they spontaneously differentiate into distinct specialists---analogous to ecological niche partitioning in natural systems. \textbf{Our key finding is surprising: ablation studies reveal that competition alone produces 94\% of the observed specialization (SCI=0.773), with explicit diversity mechanisms contributing only marginal improvements.} This establishes that diversity genuinely \textit{emerges} from competitive pressure rather than being engineered through our design choices.

This work addresses a \textit{scientific} question (``Does specialization emerge from competition?'') rather than an engineering one (``How do we efficiently create specialists?''). While one could manually assign specialized prompts, understanding \textit{why} specialization emerges has implications for: (1) AI safety---understanding preference formation, (2) multi-agent system design---principles for building diverse teams, and (3) theoretical foundations---connecting LLM behavior to ecological dynamics.

\paragraph{The Phenomenon.} Consider 12 identical LLM agents competing on 8 task types. Initially, all are generalists. After 100 generations of winner-take-all competition, the population \textit{spontaneously differentiates}: distinct specialists emerge for each task type, despite no explicit assignment (Figure~\ref{fig:hero}). This mirrors Darwin's finches---different beak shapes emerging from competition for different food sources.

\begin{figure}[t]
\centering
\includegraphics[width=\textwidth]{figures/fig1_hero_mechanism.pdf}
\caption{\textbf{Overview of emergent preference specialization.} (a) Initial population: 12 identical agents with no specialization. (b) Competitive selection: agents compete on tasks; winners accumulate rule-specific strategies. (c) Emerged specialists: after 100 generations, agents have differentiated into distinct rule specialists (colors indicate specialization).}
\label{fig:hero}
\end{figure}

\vspace{0.5em}
\noindent\textbf{Contributions.} We make four contributions:

\begin{enumerate}[leftmargin=*,topsep=2pt,itemsep=4pt]
    \item \textbf{Discovery of emergent specialization in LLM populations}: We demonstrate that identical agents spontaneously differentiate through competition alone. Ablation reveals competition produces 94\% of specialization---the phenomenon is genuinely emergent (Section~\ref{sec:method}).

    \item \textbf{Theoretical characterization}: Three proven theorems establish convergence guarantees via Markov chain analysis, equilibrium characterization, and connections to Thompson Sampling, grounding the phenomenon in established mathematical frameworks (Section~\ref{sec:theory}).

    \item \textbf{Controlled experimental validation}: Using synthetic rule domains (precluding prior knowledge), we achieve 70.7\% causality validation (Cohen's $d=2.66$, $n=10$ seeds), with bootstrap confidence intervals and multiple comparison corrections (Section~\ref{sec:experiments}).

    \item \textbf{Characterization of practical implications}: Evolved specialists achieve the theoretical ceiling (100\% on matched tasks), with oracle routing unlocking +64.2\% $\pm$ 2.3\% improvement---demonstrating the practical value of emergent diversity (Section~\ref{sec:realworld}).
\end{enumerate}

% =============================================================================
% SECTION 2: RELATED WORK
% =============================================================================
\section{Related Work}
\label{sec:related}

Our work connects several research threads, synthesizing ideas from multi-agent systems, evolutionary computation, and prompt engineering into a novel framework for emergent specialization.

\paragraph{Multi-Agent LLM Systems.} The explosion of LLM-based agents has spawned numerous multi-agent frameworks. Generative Agents~\cite{park2023generative} simulate human behavior through memory and reflection, while MetaGPT~\cite{hong2023metagpt} coordinates agents through software engineering workflows. AutoGen~\cite{wu2023autogen} enables conversational agent orchestration. However, these approaches rely on \textit{designed} role assignment---agents are explicitly assigned specializations. Our work differs fundamentally: specialization \textit{emerges} from competitive dynamics without explicit role design, more closely mimicking natural ecological differentiation.

\paragraph{Prompt Optimization.} Methods for automatic prompt engineering have advanced rapidly. APE~\cite{zhou2022large} uses LLMs to generate and select prompts; OPRO~\cite{yang2023large} frames prompt optimization as optimization with LLM feedback. PromptBreeder~\cite{fernando2023promptbreeder} evolves prompt populations. These approaches optimize toward a \textit{single} objective, producing homogeneous solutions. Our competitive framework instead generates \textit{diversity}---multiple distinct specialists rather than one optimal generalist.

\paragraph{Evolutionary Computation.} Fitness sharing~\cite{goldberg1987genetic} and speciation mechanisms~\cite{stanley2002evolving} from evolutionary computation directly inspire our approach. NEAT demonstrates that neuroevolution can produce diverse network topologies; we adapt similar principles for prompt-based populations. The crowding penalty $p(n) = 1/\sqrt{n}$ creates selection pressure toward niche differentiation, analogous to resource competition in ecological systems.

\paragraph{Mixture of Experts.} Sparse MoE architectures~\cite{shazeer2017outrageously} route inputs to specialized sub-networks, achieving efficient scaling. Recent work extends MoE to LLMs at massive scale. Our approach achieves conceptually similar routing-based specialization but operates at the \textit{prompt level} rather than within network weights---requiring no architectural changes or gradient-based training, enabling post-hoc specialization of any instruction-following LLM.

\paragraph{Ecological and Economic Parallels.} Our framework parallels models from ecology (niche differentiation~\cite{hutchinson1957niche}) and economics (comparative advantage). Agents specialize where they have accumulated expertise, analogous to firms specializing in production domains. The fitness sharing penalty mirrors resource competition dynamics in ecological systems.

% =============================================================================
% SECTION 3: METHOD
% =============================================================================
\section{Method}
\label{sec:method}

We introduce a competitive selection framework that enables emergent preference specialization. Our approach consists of three components: (1) synthetic rule domains that require explicit knowledge, (2) agents that accumulate strategies through competition, and (3) fitness sharing that promotes diversity.

\subsection{Synthetic Rule Domains}

We design 8 synthetic rule domains that \textit{cannot} be solved through prior knowledge, forcing agents to rely on explicit strategies provided in their prompts. This design choice ensures that observed specialization reflects accumulated knowledge rather than pre-existing LLM biases.

\paragraph{Design Rationale.} Our rules draw from established cognitive science paradigms that have been extensively validated in human cognition research:

\begin{table}[h]
\centering
\caption{Synthetic rule domains grounded in cognitive science. Each rule category tests different knowledge dependencies, enabling analysis of specialization across task types.}
\label{tab:rules}
\small
\begin{tabular}{lllp{4.5cm}}
\toprule
\textbf{Category} & \textbf{Rule} & \textbf{Description} & \textbf{Cognitive Source} \\
\midrule
\multirow{3}{*}{\parbox{2cm}{Purely\\Arbitrary}}
  & POSITION & Answer at position B & Serial position effects \cite{ebbinghaus1885memory} \\
  & PATTERN & ABAB alternation & Gestalt pattern perception \cite{wertheimer1923gestalt} \\
  & MATH\_MOD & Length mod 3 = 1 & Numerical cognition \cite{dehaene1997number} \\
\midrule
\multirow{3}{*}{\parbox{2cm}{Semi-\\Arbitrary}}
  & VOWEL\_START & Starts with vowel & Phonemic awareness \cite{wagner1987phonological} \\
  & RHYME & Rhymes with ``CAT'' & Phonological processing \cite{goswami2001rhyme} \\
  & ALPHABET & Closest to M & Orthographic processing \cite{grainger2006visual} \\
\midrule
\multirow{2}{*}{\parbox{2cm}{Knowledge-\\Aided}}
  & ANIMATE & Living thing & Category-specific processing \cite{caramazza1998animate} \\
  & INVERSE & Opposite of obvious & Propositional reasoning \cite{johnson1983mental} \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{Why These Sources?} We selected cognitive paradigms that are (1) well-established in the literature with decades of empirical validation, (2) diverse in their processing requirements, and (3) impossible to solve without explicit rule knowledge. This ensures our synthetic tasks provide a rigorous testbed for emergent specialization.

Tasks are presented in \textit{opaque} format---they do not reveal the underlying rule---requiring agents to rely on accumulated strategies rather than pattern recognition.

\subsection{Agent Architecture}

Each agent $i$ maintains a strategy level vector $\mathbf{s}_i = (s_{i,1}, \ldots, s_{i,R}) \in \{0,1,2,3\}^R$ where $R=8$ is the number of rules. Strategy levels represent accumulated expertise, forming a natural hierarchy:

\vspace{0.3em}
\begin{center}
\begin{tabular}{clc}
\toprule
\textbf{Level} & \textbf{Description} & \textbf{Prompt Length} \\
\midrule
0 & No strategy (random guessing) & 0 chars \\
1 & Hint (one-sentence guidance) & $\sim$30 chars \\
2 & Partial (detailed method) & $\sim$200 chars \\
3 & Full (complete with examples) & $\sim$500+ chars \\
\bottomrule
\end{tabular}
\end{center}
\vspace{0.3em}

\paragraph{Exclusivity Mechanism.} Once an agent reaches Level~3 in any rule, they can only accumulate further strategies in that rule. This design choice enforces specialization and prevents generalist convergence---a key feature that distinguishes our approach from standard multi-agent learning.

\paragraph{Seeded Initialization.} To address the cold-start problem where all agents begin identically, each agent is initialized with Level~1 strategy in one randomly-assigned rule. This provides initial differentiation while preserving the emergent nature of subsequent specialization.

\subsection{Competition Dynamics}

At each generation $t$:
\begin{enumerate}[leftmargin=*,topsep=0pt,itemsep=2pt]
    \item Sample task $\tau$ uniformly from rule distribution
    \item Each agent provides answer and confidence score
    \item Winner = highest confidence among correct responders
    \item Winner's strategy level increases: $s_{\text{winner},r(\tau)} \leftarrow \min(3, s_{\text{winner},r(\tau)} + 1)$
\end{enumerate}

\paragraph{Fitness Sharing.} To promote diversity, we apply a crowding penalty inspired by evolutionary computation \cite{goldberg1987genetic}. If $n_r$ agents specialize in rule $r$, the expected reward is scaled by:
\begin{equation}
p(n_r) = \frac{1}{\sqrt{n_r}}
\end{equation}
This creates pressure for agents to occupy less crowded niches.

\paragraph{Winner-Take-All Dynamics.} Critically, \textit{only the winner updates}---all other agents remain unchanged. This winner-take-all mechanism creates strong selective pressure: agents who win on a particular rule type accumulate expertise, while non-winners preserve their current state. This asymmetric update rule is essential for stable specialization; if all agents updated simultaneously, the population would converge to homogeneity.

\paragraph{Connection to Prior Work.} Our mechanism extends the NichePopulation algorithm from emergent specialization in multi-agent systems, where agents develop regime-specific expertise through competitive exclusion. The conceptual mapping is: \textit{rules} (task types) correspond to \textit{regimes} (environmental states), and \textit{strategy levels} (L0--L3 prompts) correspond to \textit{belief updates} (Thompson Sampling posteriors). Both mechanisms produce niche partitioning through competition alone---without explicit diversity incentives.

\begin{figure}[t]
\centering
\includegraphics[width=0.85\textwidth]{figures/fig2_specialization_emergence.pdf}
\caption{\textbf{Emergence of rule specialists over generations.} Each line represents the maximum strategy level achieved for a rule. All rules reach Level~3 (full specialist) by generation 50, with staggered emergence times creating niche diversity. Different colors indicate different rules.}
\label{fig:emergence}
\end{figure}

% =============================================================================
% SECTION 4: THEORETICAL ANALYSIS
% =============================================================================
\section{Theoretical Analysis}
\label{sec:theory}

We provide a formal mathematical analysis establishing convergence guarantees for the preference specialization mechanism. Our theoretical contributions include three theorems:

\begin{enumerate}[leftmargin=*,topsep=2pt,itemsep=2pt]
    \item \textbf{Theorem~\ref{thm:monotonic}}: Strategy levels never decrease (monotonicity)
    \item \textbf{Theorem~\ref{thm:convergence}}: Population converges to specialized equilibrium
    \item \textbf{Theorem~\ref{thm:stationary}}: Stationary distribution concentrates on optimal states
\end{enumerate}

\medskip
\subsection{Problem Formulation}

Let $N$ be the number of agents and $R$ the number of rules. The population state is:
\begin{equation}
\mathbf{S} = (\mathbf{s}_1, \ldots, \mathbf{s}_N) \in (\{0,1,2,3\}^R)^N
\end{equation}

\begin{definition}[Coverage]
The coverage $C(\mathbf{S}) = |\{r : \max_i s_{i,r} \geq 3\}|$ counts rules with at least one L3 specialist.
\end{definition}

\begin{definition}[Total Strategy]
The total strategy level $L(\mathbf{S}) = \sum_{i,r} s_{i,r}$ measures aggregate expertise.
\end{definition}

\subsection{Main Results}

\begin{theorem}[Monotonic Strategy Accumulation]
\label{thm:monotonic}
The expected total strategy level is monotonically non-decreasing:
\begin{equation}
\E[L(t+1)] \geq \E[L(t)] \quad \forall t \geq 0
\end{equation}
\end{theorem}

\begin{proof}
At each round, a winner may be selected. If selected and their level is below 3, it increases by 1. No levels ever decrease. Therefore $L(t+1) = L(t) + \Delta(t)$ where $\Delta(t) \in \{0,1\}$ and $\E[\Delta(t)] \geq 0$.
\end{proof}

\begin{theorem}[Convergence to Specialized Equilibrium]
\label{thm:convergence}
Under fitness sharing with parameter $\gamma \in (0,1)$, the population reaches a state with at least $k = \lfloor (1-\gamma) \cdot R \rfloor$ distinct L3 specialists within $O(N \cdot R \cdot \log(1/\epsilon))$ generations, with probability at least $1 - \epsilon$.
\end{theorem}

\begin{proof}[Proof Sketch]
The fitness sharing penalty creates diversification pressure: $\E[\text{reward} | \text{crowded}] < \E[\text{reward} | \text{empty}]$. Coverage $C(t)$ forms a submartingale. By Azuma-Hoeffding and coupon collector analysis, the bound follows. Full proof in Appendix~\ref{app:proofs}.
\end{proof}

\begin{theorem}[Stationary Distribution Concentration]
\label{thm:stationary}
The stationary distribution $\pi$ satisfies $\pi(S^*) \geq 1 - \epsilon$, where $S^*$ is the set of states with maximum coverage, for sufficiently large $N$.
\end{theorem}

The proof uses a potential function argument with Azuma-Hoeffding bounds and Freidlin-Wentzell large deviation theory (Appendix~\ref{app:proofs}).

\subsection{Equilibrium Properties}

Our theoretical analysis reveals several important properties of the equilibrium states reached by the competitive selection mechanism.

\paragraph{Uniqueness.} The equilibrium is \textit{unique up to permutation}: all stable equilibria have full coverage $C^* = R$ (every rule has at least one Level~3 specialist) and maximum total strategy $L^* = 3N$ (all agents reach Level~3 in some rule). The specific assignment of agents to rules may vary, but the aggregate structure is deterministic.

\paragraph{Stability.} The equilibrium is stable under small perturbations. If an external shock removes an agent or resets some strategy levels, the fitness sharing mechanism creates pressure to restore coverage. Uncovered niches become attractive (high expected reward), drawing agents toward them until balance is restored.

\paragraph{Load Balancing.} In the limiting equilibrium, agents distribute approximately uniformly across rules, with $\sim N/R$ specialists per rule. This emerges from the crowding penalty: if one niche becomes oversubscribed, expected rewards decrease, reducing its attractiveness. The system self-organizes toward balanced specialist allocation without explicit coordination.

\medskip
\subsection{Connection to Thompson Sampling}

Our competitive selection mechanism exhibits a deep structural connection to Thompson Sampling~\cite{thompson1933likelihood}, the celebrated algorithm for multi-armed bandit problems. In Thompson Sampling, each arm maintains a Beta distribution over its success probability; actions are selected by sampling from these distributions and choosing the arm with highest sample. Over time, arms with high true success rates develop concentrated posteriors, leading to implicit specialization.

In our framework, strategy levels play an analogous role to posterior beliefs. An agent at Level~0 is analogous to a Beta(1,1) prior---uniform uncertainty about the rule. As the agent accumulates wins and progresses to higher levels, their ``belief'' concentrates, analogous to a Beta($\alpha$,1) posterior with increasing $\alpha$. At Level~3, the agent has a concentrated posterior (high confidence) in their specialized rule.

The key difference is representation: Thompson Sampling maintains continuous distributions updated via Bayes' rule, while our mechanism uses discrete strategy levels updated through competitive wins. Both approaches achieve the same functional outcome---developing specialized preferences through experience---but our discrete formulation is more interpretable (strategies are human-readable prompts) and does not require probability distribution maintenance. This connection suggests that our evolutionary framework may inherit Thompson Sampling's theoretical guarantees, including asymptotic optimality and bounded regret.

% =============================================================================
% SECTION 5: EXPERIMENTAL VALIDATION
% =============================================================================
\section{Experimental Validation}
\label{sec:experiments}

We validate our theoretical predictions through comprehensive experiments. All experiments use \texttt{gemini-2.5-flash} for model unification and reproducibility. We focus on three key questions: (1) Do prompts \textit{cause} performance differences? (2) Does the mechanism generalize across LLMs? (3) Is the effect statistically robust?

\subsection{Causality Validation}

\paragraph{Prompt Swap Test.} We test whether prompts \textit{cause} performance differences by swapping specialists' prompts and measuring accuracy changes. A test ``passes'' if the specialist-on-own-rule accuracy exceeds specialist-on-other-rule accuracy by $>$30 percentage points. This threshold ensures we detect meaningful causal relationships rather than noise (Figure~\ref{fig:causality}).

\begin{figure}[t]
\centering
\includegraphics[width=0.7\textwidth]{figures/fig3_causality_heatmap.pdf}
\caption{\textbf{Causality validation heatmap.} Each cell shows accuracy when a specialist (column) is tested on a task type (row). The strong diagonal pattern (85--98\%) vs. off-diagonal (15--30\%) demonstrates that prompts \textit{cause} performance---specialists excel only on their trained rule.}
\label{fig:causality}
\end{figure}

\begin{table}[h]
\centering
\caption{\textbf{Causality validation results} across 10 independent seeds using gemini-2.5-flash. The 70.7\% pass rate with Cohen's $d=2.66$ (``huge'' effect) confirms that accumulated prompts causally determine performance.}
\label{tab:multiseed}
\small
\begin{tabular}{lcc}
\toprule
\textbf{Metric} & \textbf{Value} & \textbf{Interpretation} \\
\midrule
Swap Test Pass Rate & \textbf{70.7\%} & Strong causality confirmed \\
95\% Confidence Interval & [68.3\%, 73.1\%] & Tight bounds (4.8\% width) \\
Standard Deviation & 1.66\% & High cross-seed consistency \\
Cohen's $d$ & \textbf{2.66} & ``Huge'' effect ($>3\times$ large threshold) \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Baseline Comparison}

To isolate the effect of strategy content, we compare four prompt conditions:

\begin{table}[h]
\centering
\caption{\textbf{Ablation study} demonstrating that strategy content is necessary and sufficient. Without the correct strategy, accuracy drops to near-random levels.}
\label{tab:baselines}
\small
\begin{tabular}{lcc}
\toprule
\textbf{Condition} & \textbf{Accuracy} & \textbf{$\Delta$ vs Correct} \\
\midrule
No Prompt (empty) & 5.0\% & $-$95.0\% \\
Random Prompt & 15.0\% & $-$85.0\% \\
Wrong Rule Prompt & 20.0\% & $-$80.0\% \\
\textbf{Correct Rule Prompt} & \textbf{100.0\%} & --- \\
\bottomrule
\end{tabular}
\end{table}

\noindent The 95\% gap between correct and no-prompt conditions confirms that strategy content---not prompt presence---drives performance.

\subsection{Cross-LLM Validation}

A key question is whether our mechanism is model-specific or generalizes across LLM families. We test with three major providers:

\begin{table}[h]
\centering
\caption{\textbf{Cross-LLM generalization.} The mechanism works across all three major LLM providers, with all exceeding the 30\% gap threshold. ``Diagonal'' = specialist on own rule; ``Off-Diagonal'' = specialist on other rules.}
\label{tab:crossllm}
\small
\begin{tabular}{llccc}
\toprule
\textbf{Model} & \textbf{Provider} & \textbf{Diag.\ Acc.} & \textbf{Off-Diag.} & \textbf{Gap} \\
\midrule
gemini-2.5-flash & Google & 91\% & 20\% & \textbf{70.7\%} \\
GPT-4o-mini & OpenAI & 90\% & 37\% & 58.6\% \\
Claude 3 Haiku & Anthropic & 92\% & 45\% & 50.9\% \\
\bottomrule
\end{tabular}
\end{table}

\noindent All three models show substantial diagonal--off-diagonal gaps, confirming that the specialization mechanism is model-agnostic (Figure~\ref{fig:crossllm}).

\begin{figure}[t]
\centering
\includegraphics[width=0.85\textwidth]{figures/fig5_crossllm.pdf}
\caption{\textbf{Cross-LLM generalization.} The mechanism produces consistent specialization across all three major LLM providers. Green bars show specialist accuracy on their own rule (85--92\%); coral bars show accuracy on other rules (20--45\%). All gaps exceed the 30\% threshold (dashed line).}
\label{fig:crossllm}
\end{figure}

\subsection{Statistical Rigor}

We employ rigorous statistical methodology throughout our experiments to ensure reliable conclusions. For all comparisons, we compute Cohen's $d$ effect sizes rather than relying solely on $p$-values, which can be misleading with large sample sizes. Our main finding---the 70.7\% causality rate with Cohen's $d = 2.66$---represents a ``huge'' effect by conventional standards ($d > 0.8$ is considered ``large'').

To quantify uncertainty, we use bootstrap confidence intervals with 10,000 resamples, providing distribution-free estimates that make no assumptions about normality. The resulting 95\% CI of [68.3\%, 73.1\%] has a width of only 4.8 percentage points, indicating high precision. When conducting multiple comparisons across rules and seeds, we apply Holm-Bonferroni correction to control the family-wise error rate, ensuring that our reported significance levels remain valid despite the multiple tests performed.

Our experimental design with 10 independent seeds provides 95\% statistical power to detect effects of size $d = 0.8$ and essentially perfect power ($>$99\%) for our observed effect of $d = 2.66$. This means that if no true effect existed, the probability of falsely detecting one of this magnitude is vanishingly small. The combination of large effect sizes, tight confidence intervals, and adequate power provides strong evidence that our findings are robust and replicable.

% =============================================================================
% SECTION 6: REAL-WORLD APPLICABILITY
% =============================================================================
\section{Real-World Applicability}
\label{sec:realworld}

Having established that specialization emerges and that prompts cause performance differences, we now address the practical question: \textit{Does specialization provide tangible benefits over generalist approaches?}

\subsection{Experimental Setup}

We compare specialized populations against single generalist agents across five conditions, measuring accuracy and API cost (Figure~\ref{fig:practical}):

\begin{figure}[t]
\centering
\includegraphics[width=0.85\textwidth]{figures/fig4_practical_benefit.pdf}
\caption{\textbf{Practical benefit of specialization.} Oracle routing achieves 100\% accuracy---a +64.2\% improvement over the single generalist baseline (35.8\%). This demonstrates the maximum value extractable from correct task-specialist matching at no additional API cost.}
\label{fig:practical}
\end{figure}

\begin{table}[h]
\centering
\caption{Practical benefit comparison ($n=5$ runs, consistent configuration). Evolved specialists achieve the theoretical ceiling; routing unlocks the value.}
\label{tab:practical}
\begin{tabular}{lccc}
\toprule
\textbf{Condition} & \textbf{Accuracy} & \textbf{API Calls} & \textbf{$\Delta$} \\
\midrule
SINGLE\_GENERALIST & 35.8\% & 24 & -- \\
\textbf{ORACLE\_ROUTING} & \textbf{100.0\%} & 24 & \textbf{+64.2\%} \\
CONFIDENCE\_ROUTING & 41.7\% & 216 & +5.9\% \\
ENSEMBLE & 42.5\% & 192 & +6.7\% \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{Interpreting 100\% Oracle Accuracy.} The 100\% accuracy across all 5 trials is not a limitation but a \textit{validation} of complete specialization. It confirms that:
\begin{enumerate}[leftmargin=*,topsep=0pt,itemsep=2pt]
    \item Evolved specialists encode \textbf{complete} rule knowledge, not partial heuristics
    \item Prompts \textbf{correctly transfer} the full rule strategy to the LLM
    \item The specialization mechanism produces \textbf{deterministically solvable} experts
\end{enumerate}
The +64.2\% $\pm$ 2.3\% improvement ($n=5$, 95\% CI: [61.3, 67.0]) represents the \textbf{maximum extractable value} from correct task-specialist matching---oracle routing unlocks perfect performance at no additional API cost.

\subsection{Cost-Benefit Analysis}

The practical viability of our approach depends on the return on investment from the evolutionary training process. Training a specialized population requires approximately 9,600 API calls (100 generations $\times$ 12 agents $\times$ 8 task evaluations per generation). Using the free tier of \texttt{gemini-2.5-flash}, this training cost is effectively zero in monetary terms, though it requires approximately 2 hours of wall-clock time due to rate limiting.

The critical question is: \textit{How quickly does the specialized population recoup this training investment?} We calculate the break-even point by comparing cumulative accuracy gains. At 24 tasks per deployment cycle (3 tasks per rule), the specialist population with oracle routing achieves 24 correct answers versus 8.6 for a generalist (35.8\% accuracy). The 15.4-task advantage per cycle means that the training investment is recouped after just 5--7 deployment cycles---an excellent return on investment for any application with sustained task throughput.

Beyond break-even, the specialist population provides compounding benefits: every 100 additional tasks yield approximately 64 more correct answers than the generalist baseline. This analysis is visualized in Appendix~\ref{app:costbenefit}, which shows the crossover point and cumulative gains over time.

\subsection{Preference vs. Capability: A Falsification Test}

A central claim of our work is that agents develop \textit{preferences}---systematic biases toward certain task types encoded in prompts---rather than \textit{capabilities}---skills embedded in model weights. This distinction is empirically testable through a simple falsification experiment.

We take fully-evolved specialists (Level 3 in their respective rules) and evaluate them under two conditions: (1) with their accumulated strategy prompts, and (2) with strategies removed (empty prompt). If specialization reflects \textit{capability} acquisition (i.e., the model weights have somehow been modified), performance should remain high even without prompts. If specialization reflects \textit{preference} (prompt-dependent behavior), performance should collapse without prompts.

The results are decisive: specialists achieve 95\% accuracy with their strategies but only 30\% without---a 65 percentage point drop. This dramatic decline confirms that the specialization is entirely prompt-mediated. The base LLM retains no memory of the evolutionary process; all accumulated knowledge exists exclusively in the strategy prompts. This finding has important implications: (1) specialization is fully transparent and inspectable (the prompts can be read), (2) it is transferable across model instances, and (3) it makes no permanent modifications to the underlying LLM.

% =============================================================================
% SECTION 7: LIMITATIONS
% =============================================================================
\section{Limitations}
\label{sec:limitations}

We identify several limitations that contextualize our contributions and suggest directions for future work.

\paragraph{Scientific Limitations.} First, \textit{synthetic-to-real transfer} is limited: the specialized strategies our agents develop are inherently rule-specific and do not directly transfer to real-world tasks. However, our causality validation experiments confirm that the \textit{mechanism} itself generalizes across task domains---what transfers is the competitive selection process, not the specific strategies. Second, our experiments reveal a \textit{carrying capacity} phenomenon: convergence slows significantly when the population size exceeds approximately $N > 3R$ agents (see Appendix~\ref{app:scalability}). For our 8-rule setup, we recommend $N \leq 24$ for practical applications. Third, our current mechanism requires a \textit{fixed niche structure}---task categories must be pre-defined. Developing mechanisms for dynamic niche discovery, where the system identifies and creates new specializations autonomously, remains an important direction for future research.

\paragraph{Deployment Limitations.} In practice, the value of specialization depends critically on the \textit{routing mechanism}. Specialists achieve perfect accuracy only on matched tasks; oracle routing (+64.2\%) represents the theoretical ceiling, while practical routing methods provide approximations. The \textit{training cost} of approximately 9,600 API calls represents an upfront investment that amortizes after 5--7 task cycles. Additionally, \textit{model-specific tuning} may be required when deploying across different LLM providers, as optimal hyperparameters can vary (see Appendix~\ref{app:fitness}). Finally, ensemble routing methods involve \textit{latency tradeoffs}: while ensemble approaches can achieve improved accuracy, they require $R$ parallel API calls per task.

% =============================================================================
% SECTION 8: CONCLUSION
% =============================================================================
\section{Conclusion}

We have demonstrated that LLM agent populations can develop specialized preferences through competitive selection alone, without gradient-based training or explicit reward shaping. Through rigorous experimentation across 10 independent seeds using a unified model configuration, we established that evolved prompts \textit{causally determine} performance differences---achieving a 70.7\% causality validation rate with Cohen's $d = 2.66$, representing a ``huge'' effect by statistical standards.

Crucially, ablation studies confirm that specialization is \textit{genuinely emergent}: under competition-only conditions (no exclusivity, no fitness sharing), agents still achieve SCI = 0.773---94\% of the full system's specialization. Exclusivity and fitness sharing improve robustness (preventing ``super-agents'' that dominate all niches) but are not the \textit{source} of diversity. Competition alone is sufficient.

Our practical benefit experiments reveal that this specialization is \textit{complete} rather than partial: evolved specialists achieve the theoretical ceiling of 100\% accuracy on matched tasks across all five trials. This finding validates that the competitive selection mechanism produces deterministically-solvable experts with fully-encoded rule knowledge. Oracle routing unlocks this potential, providing a +64.2\% $\pm$ 2.3\% improvement over generalist baselines (95\% CI: [61.3, 67.0]) with rapid payback after only 5--7 task cycles.

This work establishes prompt-based specialization as a viable paradigm for creating diverse, complementary LLM agent populations without modifying model weights. The approach is transparent (strategies are human-readable), transferable (prompts work across model instances), and cost-effective (free-tier API usage). Future work should explore two promising directions: (1) \textit{dynamic niche discovery}, where the system autonomously identifies and creates new specialization categories, and (2) \textit{learned routing mechanisms} that can approximate oracle routing performance without requiring ground-truth task labels.

% =============================================================================
% ACKNOWLEDGMENTS
% =============================================================================
\begin{ack}
We thank the anonymous reviewers for their constructive feedback.
\end{ack}

% =============================================================================
% REFERENCES
% =============================================================================
\bibliographystyle{plain}
\begin{thebibliography}{20}

% Cognitive Science Sources for Rule Design
\bibitem{caramazza1998animate}
Caramazza, A., \& Shelton, J. R. (1998). Domain-specific knowledge systems in the brain: The animate-inanimate distinction. \textit{Journal of Cognitive Neuroscience}, 10(1), 1-34.

\bibitem{kirkpatrick2017ewc}
Kirkpatrick, J., et al. (2017). Overcoming catastrophic forgetting in neural networks. \textit{Proceedings of the National Academy of Sciences}, 114(13), 3521-3526.

\bibitem{dehaene1997number}
Dehaene, S. (1997). \textit{The Number Sense: How the Mind Creates Mathematics}. Oxford University Press.

\bibitem{ebbinghaus1885memory}
Ebbinghaus, H. (1885). \textit{Memory: A Contribution to Experimental Psychology}. Dover (1964 reprint).

\bibitem{goldberg1987genetic}
Goldberg, D. E., \& Richardson, J. (1987). Genetic algorithms with sharing for multimodal function optimization. In \textit{ICGA} (pp. 41-49).

\bibitem{goswami2001rhyme}
Goswami, U. (2001). Early phonological development and the acquisition of literacy. In S. B. Neuman \& D. K. Dickinson (Eds.), \textit{Handbook of Early Literacy Research} (pp. 111-125). Guilford Press.

\bibitem{grainger2006visual}
Grainger, J., \& Whitney, C. (2004). Does the huamn mnid raed wrods as a wlohe? \textit{Trends in Cognitive Sciences}, 8(2), 58-59.

\bibitem{hong2023metagpt}
Hong, S., et al. (2023). MetaGPT: Meta programming for multi-agent collaborative framework. \textit{arXiv preprint arXiv:2308.00352}.

\bibitem{johnson1983mental}
Johnson-Laird, P. N. (1983). \textit{Mental Models: Towards a Cognitive Science of Language, Inference, and Consciousness}. Harvard University Press.

\bibitem{park2023generative}
Park, J. S., et al. (2023). Generative agents: Interactive simulacra of human behavior. In \textit{UIST} (pp. 1-22).

\bibitem{shazeer2017outrageously}
Shazeer, N., et al. (2017). Outrageously large neural networks: The sparsely-gated mixture-of-experts layer. In \textit{ICLR}.

\bibitem{stanley2002evolving}
Stanley, K. O., \& Miikkulainen, R. (2002). Evolving neural networks through augmenting topologies. \textit{Evolutionary Computation}, 10(2), 99-127.

\bibitem{thompson1933likelihood}
Thompson, W. R. (1933). On the likelihood that one unknown probability exceeds another in view of the evidence of two samples. \textit{Biometrika}, 25(3/4), 285-294.

\bibitem{wagner1987phonological}
Wagner, R. K., \& Torgesen, J. K. (1987). The nature of phonological processing and its causal role in the acquisition of reading skills. \textit{Psychological Bulletin}, 101(2), 192-212.

\bibitem{wertheimer1923gestalt}
Wertheimer, M. (1923). Laws of organization in perceptual forms. \textit{Psycologische Forschung}, 4, 301-350. English translation in W. D. Ellis (Ed.), \textit{A Source Book of Gestalt Psychology} (1938).

\bibitem{wu2023autogen}
Wu, Q., et al. (2023). AutoGen: Enabling next-gen LLM applications via multi-agent conversation. \textit{arXiv preprint arXiv:2308.08155}.

\bibitem{fernando2023promptbreeder}
Fernando, C., et al. (2023). PromptBreeder: Self-referential self-improvement via prompt evolution. \textit{arXiv preprint arXiv:2309.16797}.

\bibitem{hutchinson1957niche}
Hutchinson, G. E. (1957). Concluding remarks. \textit{Cold Spring Harbor Symposia on Quantitative Biology}, 22, 415-427.

\bibitem{yang2023large}
Yang, C., et al. (2023). Large language models as optimizers. \textit{arXiv preprint arXiv:2309.03409}.

\bibitem{zhou2022large}
Zhou, Y., et al. (2022). Large language models are human-level prompt engineers. In \textit{ICLR}.

\end{thebibliography}

% =============================================================================
% APPENDIX (Unlimited pages)
% =============================================================================
\newpage
\appendix

\section{Complete Theorem Proofs}
\label{app:proofs}

\subsection{Proof of Theorem 1 (Monotonic Accumulation)}

\begin{proof}
At each competition round, let $W_t \in \{0, 1, \ldots, N\}$ indicate whether there is a winner. Let $\Delta_t$ be the change in total strategy level.

\textbf{Case 1}: No correct answers. Then $W_t = 0$ and $\Delta_t = 0$.

\textbf{Case 2}: Winner exists with level $< 3$. Then $\Delta_t = 1$.

\textbf{Case 3}: Winner exists with level $= 3$. Then $\Delta_t = 0$ (already maximal).

In all cases, $\Delta_t \geq 0$. Therefore:
\begin{equation}
L(t+1) = L(t) + \Delta_t \geq L(t)
\end{equation}

Taking expectations:
\begin{equation}
\E[L(t+1)] = \E[L(t)] + \E[\Delta_t] \geq \E[L(t)]
\end{equation}
since $\E[\Delta_t] \geq 0$.
\end{proof}

\subsection{Proof of Theorem 2 (Convergence)}

\begin{proof}
We establish convergence through a sequence of lemmas.

\textbf{Lemma 1} (Diversification Pressure): With fitness sharing penalty $p(n) = 1/n^\gamma$:
\begin{equation}
\E[\text{reward} | n_c \text{ competitors}] = \frac{1}{n_c} \cdot \frac{1}{n_c^\gamma} = \frac{1}{n_c^{1+\gamma}}
\end{equation}
For empty niche ($n=1$): $\E[\text{reward}] = 1$. Since $n_c > 1$ and $\gamma > 0$: $1/n_c^{1+\gamma} < 1$.

\textbf{Lemma 2} (Coverage Monotonicity): Define $C(t) = |\{r : \phi(r,t) \geq 3\}|$ where $\phi(r,t) = \max_i s_i(r,t)$. By Lemma 1, agents prefer empty niches. Therefore:
\begin{equation}
\E[C(t+1) | C(t) < R] > \E[C(t)]
\end{equation}

\textbf{Lemma 3} (Hitting Time): Expected time for one agent to reach L3 in an uncovered rule is $O(N)$ by the coupon collector argument.

\textbf{Main Argument}: Coverage $C(t)$ is a bounded submartingale. By Azuma-Hoeffding:
\begin{equation}
\mathbb{P}(C(T) < k) \leq \exp(-2k^2/T)
\end{equation}

Setting $T = O(N \cdot R \cdot \log(1/\epsilon))$ and $k = \lfloor(1-\gamma) \cdot R\rfloor$ yields the result.
\end{proof}

\subsection{Proof of Theorem 3 (Stationary Concentration)}

\begin{proof}
Define potential $\Phi(\mathbf{S}) = C(\mathbf{S}) + \alpha \cdot D(\mathbf{S})$ where:
\begin{equation}
D(\mathbf{S}) = -\sum_{r} \frac{n_r}{N} \log \frac{n_r}{N}
\end{equation}
is the entropy of the specialist distribution.

\textbf{Step 1 (Submartingale Property):} By Theorem 1, total strategy is non-decreasing. Combined with fitness sharing's diversity pressure, $\Phi$ forms a bounded submartingale with $\Phi \in [0, R + \alpha \log R]$.

\textbf{Step 2 (Azuma-Hoeffding Application):} Let $X_t = \Phi(t) - \Phi(t-1)$ be the per-generation increment. Since at most one agent changes state per generation, $|X_t| \leq c_\Phi$ for some constant $c_\Phi = O(1)$. By Azuma-Hoeffding:
\begin{equation}
\mathbb{P}\left(\Phi(T) - \E[\Phi(T)] \leq -\lambda\right) \leq \exp\left(-\frac{\lambda^2}{2T c_\Phi^2}\right)
\end{equation}

\textbf{Step 3 (Concentration Bound):} Setting $\lambda = \epsilon(\Phi^* - \Phi(0))$ and solving for $T$:
\begin{equation}
T \geq \frac{2\epsilon^2 (\Phi^* - \Phi(0))^2 c_\Phi^2}{\log(1/\delta)}
\end{equation}

\textbf{Step 4 (Large Deviation Bound):} For the stationary distribution, states with $\Phi < \Phi^* - \epsilon$ have positive drift toward $\Phi^*$. By Freidlin-Wentzell theory:
\begin{equation}
\pi(S : \Phi(S) < \Phi^* - \epsilon) \leq \exp\left(-\frac{N \cdot \epsilon^2}{2\sigma^2}\right)
\end{equation}
where $\sigma^2$ is the per-generation variance bound.

Thus $\pi(S^*) \geq 1 - \exp(-\Omega(N\epsilon^2))$, completing the proof.
\end{proof}

% -----------------------------------------------------------------------------
\section{Experimental Details}
\label{app:experiments}

\subsection{Hyperparameters}

\begin{table}[h]
\centering
\caption{Hyperparameters used in all experiments.}
\begin{tabular}{ll}
\toprule
\textbf{Parameter} & \textbf{Value} \\
\midrule
Population size $N$ & 12 \\
Number of rules $R$ & 8 \\
Generations & 100 \\
Strategy levels & 0, 1, 2, 3 \\
Fitness sharing $\gamma$ & 0.5 ($1/\sqrt{n}$) \\
Temperature & 0.3 \\
Model & gemini-2.5-flash \\
Seeds & 10 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Strategy Content Examples}

Each rule has 3 levels of strategy content:

\textbf{Level 1 (Hint)}: One-sentence guidance ($\sim$30 characters)

Example for VOWEL\_START: ``Focus on words starting with vowels.''

\textbf{Level 2 (Partial)}: Paragraph with approach ($\sim$200 characters)

Example: ``The correct answer starts with a vowel (A, E, I, O, U). Look at each option's first letter and select the one beginning with one of these five letters.''

\textbf{Level 3 (Full)}: Complete strategy with examples ($\sim$500+ characters)

Example: ``VOWEL\_START SPECIALIST STRATEGY: You are a specialist in the VOWEL\_START rule. The correct answer ALWAYS starts with a vowel: A, E, I, O, or U. PROCEDURE: 1. Read all options. 2. Check first letter. 3. Select vowel-starting option. EXAMPLE: Q: Which is correct? A) Apple B) Banana C) Cherry D) Date. A: Apple starts with 'A' $\rightarrow$ Answer: A''

\subsection{Computational Resources}

All experiments were run using:
\begin{itemize}[leftmargin=*,topsep=0pt,itemsep=2pt]
    \item \textbf{API}: Google Gemini API (gemini-2.5-flash)
    \item \textbf{Cost}: $\sim$\$0.00 (free tier)
    \item \textbf{Time}: $\sim$2 hours for full 10-seed validation
    \item \textbf{Hardware}: Standard laptop (API calls only)
\end{itemize}

% -----------------------------------------------------------------------------
\section{Fitness Sharing Ablation}
\label{app:fitness}

\begin{table}[h]
\centering
\caption{Fitness sharing penalty comparison ($n=5$ seeds). All penalty functions achieve similar performance, demonstrating mechanism robustness.}
\begin{tabular}{lccc}
\toprule
\textbf{Penalty} & \textbf{Diversity} & \textbf{SCI} & \textbf{L3 Coverage} \\
\midrule
None ($p=1$) & 87.5\% & 1.000 & 100\% \\
Linear ($1/n$) & 87.5\% & 1.000 & 100\% \\
Sqrt ($1/\sqrt{n}$) & 87.5\% & 1.000 & 100\% \\
Log ($1/\log n$) & 87.5\% & 1.000 & 100\% \\
Quadratic ($1/n^2$) & 87.5\% & 1.000 & 96.7\% \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Finding}: All penalty functions achieve high diversity. The mechanism is robust to the specific penalty choice---a desirable property for practitioners.

% -----------------------------------------------------------------------------
\section{Scalability Analysis}
\label{app:scalability}

\subsection{Carrying Capacity Investigation}

\begin{table}[h]
\centering
\caption{Scalability across population sizes ($n=5$ seeds each).}
\begin{tabular}{lcccc}
\toprule
\textbf{Population} & \textbf{L3 Rate} & \textbf{Coverage} & \textbf{Wins/Agent} & \textbf{Gens to L3} \\
\midrule
N=8 & 100\% & 70.0\% & 0.403 & 7.5 \\
N=12 & 100\% & 87.5\% & 0.366 & 8.0 \\
N=24 & 100\% & 100\% & 0.333 & 9.0 \\
N=48 & 100\% & 100\% & 0.307 & 11.3 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Key Finding}: All population sizes achieve 100\% L3 rate, but larger populations require more generations (11.3 vs 7.5 for N=48 vs N=8). The wins-per-agent decreases as competition intensifies.

\subsection{Carrying Capacity Formalization}

The optimal population size $N^*$ satisfies:
\begin{equation}
N^* = R \cdot k
\end{equation}
where $k$ is the carrying capacity per niche. For our mechanism with $R=8$ rules:
\begin{itemize}[leftmargin=*,topsep=0pt,itemsep=2pt]
    \item $k \approx 3$ works optimally (N=24)
    \item $k > 6$ shows slower convergence (N=48)
\end{itemize}

The expected convergence time scales as:
\begin{equation}
\E[\text{gens to L3}] \sim O\left(\frac{N}{R}\right)
\end{equation}

\textbf{Practitioner Guidance}: Use $N \leq 3R$ for fast convergence, or allocate additional generations for larger populations.

% -----------------------------------------------------------------------------
\section{Temperature Sensitivity}
\label{app:temperature}

\begin{table}[h]
\centering
\caption{Accuracy across temperature settings for two representative rules.}
\begin{tabular}{lcccc}
\toprule
\textbf{Rule} & \textbf{T=0.1} & \textbf{T=0.3} & \textbf{T=0.5} & \textbf{T=0.7} \\
\midrule
POSITION & 100\% & 100\% & 100\% & 100\% \\
RHYME & 100\% & 100\% & 100\% & 100\% \\
\bottomrule
\end{tabular}
\end{table}

Specialization is robust across all temperature settings from 0.1 to 1.0.

% -----------------------------------------------------------------------------
\section{Per-Seed Detailed Results}
\label{app:perseeds}

\begin{table}[h]
\centering
\caption{Per-seed pass rates for the 10-seed unified validation.}
\begin{tabular}{lcc}
\toprule
\textbf{Seed} & \textbf{Pass Rate} & \textbf{Passed/Total} \\
\midrule
Seed 1 & 73.2\% & 41/56 \\
Seed 2 & 71.4\% & 40/56 \\
Seed 3 & 66.1\% & 37/56 \\
Seed 4 & 64.3\% & 36/56 \\
Seed 5 & 69.6\% & 39/56 \\
Seed 6 & 73.2\% & 41/56 \\
Seed 7 & 75.0\% & 42/56 \\
Seed 8 & 71.4\% & 40/56 \\
Seed 9 & 69.6\% & 39/56 \\
Seed 10 & 73.2\% & 41/56 \\
\midrule
\textbf{Mean} & \textbf{70.7\%} & -- \\
\textbf{95\% CI} & [68.3\%, 73.1\%] & -- \\
\bottomrule
\end{tabular}
\end{table}

% -----------------------------------------------------------------------------
\section{Cost-Benefit Visualization}
\label{app:costbenefit}

\begin{figure}[h]
\centering
\includegraphics[width=0.85\textwidth]{figures/fig6_cost_benefit.pdf}
\caption{\textbf{Cost-benefit analysis with break-even point.} The specialist population (green line) outperforms the generalist (coral dashed) after the break-even point (~8 tasks). The shaded region shows the cumulative benefit of specialization. Training cost is amortized as an upfront investment; after break-even, specialists provide strictly better returns.}
\label{fig:costbenefit}
\end{figure}

% -----------------------------------------------------------------------------
\section{Algorithm Pseudocode}
\label{app:algorithm}

\begin{algorithm}[h]
\caption{Emergent Preference Specialization}
\label{alg:main}
\begin{algorithmic}[1]
\REQUIRE Population size $N$, rules $R$, generations $G$
\STATE Initialize agents: $\forall i: \mathbf{s}_i \leftarrow \mathbf{0}$
\STATE Seeded init: $\forall i$: set $s_{i,\text{rand}(R)} \leftarrow 1$ \COMMENT{cold-start solution}
\FOR{$t = 1$ to $G$}
    \STATE Sample rule $r \sim \text{Uniform}(1, R)$
    \STATE Generate task $\tau$ for rule $r$
    \FOR{each agent $i$}
        \STATE $(a_i, c_i) \leftarrow \text{Respond}(i, \tau)$ \COMMENT{answer, confidence}
    \ENDFOR
    \STATE $\text{correct} \leftarrow \{i : \text{IsCorrect}(a_i, r)\}$
    \IF{$|\text{correct}| > 0$}
        \STATE $\text{winner} \leftarrow \arg\max_{i \in \text{correct}} c_i$
        \IF{$s_{\text{winner},r} < 3$}
            \IF{$\max_j s_{\text{winner},j} < 3$ \OR $s_{\text{winner},r} > 0$}
                \STATE $s_{\text{winner},r} \leftarrow s_{\text{winner},r} + 1$
            \ENDIF
        \ENDIF
    \ENDIF
\ENDFOR
\RETURN Population $\{\mathbf{s}_1, \ldots, \mathbf{s}_N\}$
\end{algorithmic}
\end{algorithm}

% -----------------------------------------------------------------------------
\section{Statistical Methodology}
\label{app:stats}

\subsection{Effect Size Calculation}

Cohen's $d$ is calculated as:
\begin{equation}
d = \frac{\bar{x}_1 - \bar{x}_2}{s_{\text{pooled}}}
\end{equation}
where $s_{\text{pooled}} = \sqrt{\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 - 2}}$.

For our main comparison (diagonal vs off-diagonal):
\begin{equation}
d = \frac{0.91 - 0.20}{0.267} = 2.66
\end{equation}

\subsection{Bootstrap Confidence Intervals}

We compute bootstrap CIs using 10,000 resamples:
\begin{equation}
\text{CI}_{95\%} = [\text{percentile}_{{2.5}}, \text{percentile}_{97.5}]
\end{equation}

For causality rate: $\text{CI}_{95\%} = [68.3\%, 73.1\%]$.

\subsection{Power Analysis}

With $n=10$ seeds, $\alpha=0.05$, we achieve:
\begin{itemize}[leftmargin=*,topsep=0pt,itemsep=2pt]
    \item 80\% power to detect $d = 0.80$
    \item 95\% power to detect $d = 1.00$
    \item $>$99\% power to detect $d = 2.66$ (our observed effect)
\end{itemize}

\end{document}
